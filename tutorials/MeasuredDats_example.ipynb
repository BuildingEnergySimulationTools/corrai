{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f8dc4",
   "metadata": {},
   "source": [
    "***Notebooks are written for Jupyter and might not display well in Github***\n",
    "\n",
    "\n",
    "# Loading and processing measured data with MeasuredDats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85508d",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to provide a comprehensive workflow for treating measured data using  **CorrAI** <code>MeasuredDats</code>.\n",
    "\n",
    "## Use case\n",
    "\n",
    "Measurements were collected from a real-scale benchmark conducted by Nobatek's BEF (Banc d'Essais Façade), which provides experimental cells for testing building façade solutions. Heat exchanges in a cell are limited to five of its faces, while the sixth face is dedicated to the tested solution. Internal temperature and hydrometry conditions can be controlled or monitored, and external conditions, such as temperatures and solar radiation, are measured.\n",
    "\n",
    "The experimental setup is presented in the following figures:\n",
    "\n",
    "| Figure 1: picture of the benchmark | Figure 2: wall layers from the inside (right) to the outside (left) |\n",
    "| :---: | :---: |\n",
    "|<img src=\"images/etics_pict.png\"  height=\"300\"> | <img src=\"images/etics_sch.png\"  height=\"300\"> |\n",
    "\n",
    "Additional details about the data:\n",
    "- The measurement campaign spanned from 07/06/2017 to 20/06/2017.\n",
    "- The acquisition timestep is probably 1 minute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768a5bb",
   "metadata": {},
   "source": [
    "# Measured data analysis and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bac0",
   "metadata": {},
   "source": [
    "Measured data are loaded using <code>pandas</code> python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    Path(r\"resources/tuto_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c929",
   "metadata": {},
   "source": [
    "Plotting the raw temperatures gives precious information on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc901bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['T_ext'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99064541",
   "metadata": {},
   "source": [
    "At first sight, a dataset may look fine, but missing values or incorrect variations are not always visible on a graph. The following steps are proposed to ensure data quality.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "- __upper__ and __lower__ values as boundaries. Measured values outside the interval are considered wrong\n",
    "- upper and lower \"__rates__\". Measured value increasing beyond or below a defined threshold are considered wrong\n",
    "\n",
    "These boundaries are set depending on the measured physical phenomenon.\n",
    "For example, the boundaries for power and temperature will be configured differently.\n",
    "\n",
    "#### 2- Missing data interpolation\n",
    "Physical models do not tolerate missing values well. Therefore, for each sensor, we provide a method to interpolate missing data. We use a linear interpolation method to fill in the gaps between missing points. Errors at the beginning or end of the time series are filled with the first or last correct value.\n",
    "\n",
    "#### 3- Reducing dataset size\n",
    "Finally, a 1-minute acquisition timestep provides a heavy dataset.\n",
    "To make the dataset more manageable, we provide an aggregation method to _resample_ the dataset. Resampling allows the data to be aggregated into larger time intervals without losing critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using MeasuredDat to perform operations on data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The <code>MeasuredDats</code> **corrai** object is designed to specify transformations to apply to a measured dataset and ti visualize their effects.\n",
    "The measured are classified in _categories_ (eg. temperature, power, control, etc.).\n",
    "The transformation can be specified at category level, or can be common to all the categories.\n",
    "At the end of the process a resampler can be specified. It can be used to align data or reduce the size of the dataset.\n",
    "<code>MeasuredDats</code> uses **Scikit Learn** _pipelines_. The transformers are <code>corrai.custom_transfomers</code> objects, they inherit from scikit base class <code>BaseEstimator</code> and <code>TransformerMixin</code>. These transformer ensure that Pandas <code>DataFrame</code> with <code>DateTimeIndex</code> are used through the process\n",
    "\n",
    "The figure below describe a \"pipeline\" that apply a series of correction to the dataset.\n",
    "\n",
    "<img src=\"images/pipe.png\"  height=\"400\">\n",
    "\n",
    "4 successive transformations are applied: 2 category transformations, a common transformation and a resampling operation.\n",
    "\n",
    "The **categories** are specified using <code>data_type_dict</code> :\n",
    "```\n",
    "category_dict = {\n",
    "    \"Temperatures\": [\"temp_1\", [\"temp_2\"],\n",
    "    \"Power\": [\"pow_1\"],\n",
    "    \"radiation\": [\"Sol_rad\"]\n",
    "    }\n",
    "```\n",
    "\n",
    "The **category transformations** are specified :\n",
    "```\n",
    "category_transformations = {\n",
    "    \"Temperatures\":{\n",
    "        \"ANOMALIES\": [\n",
    "            [\"drop_threshold\", {\"upper\": 40000, \"lower\": 0}],\n",
    "            [\"drop_time_gradient\", {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "        \"RESAMPLE\": \"mean\"\n",
    "    },\n",
    "    \"Power\": {\n",
    "        \"ANOMALIES\": [\n",
    "            [\"drop_threshold\", {\"upper\": 50, \"lower\": -2}],\n",
    "            [\"drop_time_gradient\", {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "        \"PROCESS\": [\n",
    "            [\"apply_expression\", {\"expression\": x / 1000}]\n",
    "        ],\n",
    "        \"RESAMPLE\": \"mean\"\n",
    "    },\n",
    "    \"radiation\": {}\n",
    "},\n",
    "```\n",
    "\n",
    "- The dictionary keys must match the category defined in <code>category_dict</code>\n",
    "- Each for each category you can specify as much transformer as you want. Similar name must be given in each category if you want transformer to be used in the same _\"category transformation\"_ (eg. ANOMALIES)\n",
    "- For each transformer a list of transformation is given. They are defined by a list with two elements [custom_transformer key, {custom transformer args}]\n",
    "- An optional key \"RESAMPLE\" may be given to specify the category aggregation method in case of resampling. By default, resampling method is mean\n",
    "- If the category doesn't require any transformation, specify an empty directory\n",
    "\n",
    "The **common transformations** are specified :\n",
    "\n",
    "```\n",
    "common_transformations={\n",
    "    \"COMMON\": [\n",
    "        [\"interpolate\", {\"method\": 'linear'}],\n",
    "        [\"fill_na\", {\"method\": 'bfill'}],\n",
    "        [\"fill_na\", {\"method\": 'bfill'}]\n",
    "    ]\n",
    "}\n",
    "```\n",
    "- The dictionary keys are the manes of the common transformers\n",
    "- For each transformer a list of transformation is given. They are defined by a list with two elements [custom_transformer key, {custom transformer args}]\n",
    "\n",
    "The **transformer list** :\n",
    "Lastly you can specify the order of the transformations using <code>transformers_list</code>. For example <code>transformers_list = [\"ANOMALIES\", \"COMMON\", \"PRECESS\"]</code>.\n",
    "- If <code>transformer_list</code> is left to <code>None</code>, transformers list hold all the category_transformers, than all the common transformers\n",
    "- This list can be changed at all time.\n",
    "- You don't have to use all the transformers,\n",
    "- Resampling will always be put at the end of the pipeline\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is an example for the dataset we just loaded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.measure import MeasuredDats\n",
    "from corrai.measure import get_transformers_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function <code>get_transformers_keys()</code> id designed to expose the available transformers names and help you configure <code>MeasuredDats</code>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_transformers_keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MeasuredDats(\n",
    "    data = raw_data,\n",
    "    category_dict = {\n",
    "        \"temperatures\": [\n",
    "            'T_Wall_Ins_1', 'T_Wall_Ins_2', 'T_Ins_Ins_1', 'T_Ins_Ins_2',\n",
    "            'T_Ins_Coat_1', 'T_Ins_Coat_2', 'T_int_1', 'T_int_2', 'T_ext', 'T_garde'\n",
    "        ],\n",
    "        \"illuminance\": [\"Lux_CW\"],\n",
    "        \"radiation\": [\"Sol_rad\"]\n",
    "    },\n",
    "    category_transformations = {\n",
    "        \"temperatures\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 100, \"lower\": -20}],\n",
    "                [\"drop_time_gradient\", {\"upper_rate\": 2, \"lower_rate\": 0}]\n",
    "            ],\n",
    "            \"RESAMPLE\": 'mean',\n",
    "        },\n",
    "        \"illuminance\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "            \"RESAMPLE\": 'mean',\n",
    "        },\n",
    "        \"radiation\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "            \"RESAMPLE\": 'mean',\n",
    "        }\n",
    "    },\n",
    "    common_transformations={\n",
    "\t\t\"COMMON\": [\n",
    "            [\"interpolate\", {\"method\": 'linear'}],\n",
    "\t\t    [\"fill_na\", {\"method\": 'bfill'}],\n",
    "\t\t    [\"fill_na\", {\"method\": 'bfill'}]\n",
    "        ]\n",
    "    },\n",
    "    transformers_list=[\"ANOMALIES\", \"COMMON\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that <code>transformers_list</code> could have been left to None are we are applying the only category transformer, than the common transformer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_data.get_pipeline()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_data.plot(resampling_rule=\"15T\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "id": "7c54297b",
   "metadata": {},
   "source": [
    "The <code>plot</code> method can be used to plot the data.\n",
    "\n",
    "Provide a <code>list</code> to the argument <code>cols</code> to specify the entry you want to plot.\n",
    "\n",
    "A new y axis will be created for each data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec69bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac115e7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-04-15',\n",
    "    end='2018-04-18',\n",
    "    title='Plot uncorrected data',\n",
    "    marker_raw=True,\n",
    "    line_raw=False,\n",
    "    plot_raw = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e79b06",
   "metadata": {},
   "source": [
    "Plotted data are the <code>corrected_data</code>. Use <code>plot_raw=True</code> to display raw data. This is useful to assess the impact of the correction and of the resampling methods\n",
    "\n",
    "For now no corrections have been applied, so <code>corrected_data</code> is equal to <code>data</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3932",
   "metadata": {},
   "source": [
    "\n",
    "The object <code>my_data</code> contains the original dataset and methode configuration for the correction.\n",
    "\n",
    "The <code>correction_journal</code> properties holds information on the data.\n",
    "\n",
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4db7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_data.correction_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb603",
   "metadata": {},
   "source": [
    "Before correction, the journal shows that ~2% of the data are missing for the temperature sensor and ~3% for external temperature, \"garde\" temperature and solar radiation. it corresponds to data having a timestamp, but with missing value. In this specific case, this is not related to sensors errors. 2 distinct acquisition device were used to perform the measurement. The merging of the data from the two devices created troubles in timestamp \"alignment\". Also measurement stopped a bit earlier for the second device.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "Now let's apply the remove anomalies method to delete invalid data according to the specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386abd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.remove_anomalies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed9525",
   "metadata": {},
   "source": [
    "Let's have a look at the <code>correction_journal</code>.\n",
    "Not all of it, as it stores every correction \"effect\". It will get big rapidly.\n",
    "First we want to see the new percentage of missing data after correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31dbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd878",
   "metadata": {},
   "source": [
    "It looks like the applied corrections removed several data.\n",
    "For example, the sensors measuring the cell internal temperature have now up to __4.5%__ of missing data.\n",
    "\n",
    "Few corrections were applied to the outside temperature sensor.\n",
    "\n",
    "The journal of correction holds further information on the gaps of data.\n",
    "For example if we want to know more about the missing values of <code>T_int_1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"T_int_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3f59",
   "metadata": {},
   "source": [
    "- There are 11233 gaps.\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest is 1h\n",
    "\n",
    "It is also possible to \"aggregate\" the gaps in to know when at least one of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"remove_anomalies\"][\"gaps_stats\"][\"combination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c767b8",
   "metadata": {},
   "source": [
    "- There are 28066 gaps (~10% of the dataset).\n",
    "- The size of 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The biggest gap is 1h\n",
    "\n",
    "There is not a lot of difference. It looks like the values are missing at the same timestamps.\n",
    "\n",
    "This is a good news, it means that there are a lot of periods with all data available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275e599",
   "metadata": {},
   "source": [
    "The plotting method <code>plot_gaps</code> can be used to visualize where the gap happened.\n",
    "\n",
    "This dataset holds a lot of values, sol we just plot the entry <code>'T_int_1'</code> that is supposed to have the more gaps\n",
    "\n",
    "We are interested in gaps lasting more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88573e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "my_data.plot_gaps(cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],begin='2018-03-25', end='2018-03-25', gaps_timestep=dt.timedelta(minutes=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f229b95",
   "metadata": {},
   "source": [
    "There seem to be only 1 gap greater than 15 minutes, it happens the 2018-03-25 between ~02:00 and ~3:00.\n",
    "This is the gap we identified in the correction journal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1a75e",
   "metadata": {},
   "source": [
    "We may want to access the new corrected data set to perform further investigations. It is available at <code>corrected_data</code> in <code>MeasuredDats</code> object.\n",
    "\n",
    "_Note that the original data set is left untouched in <code>data</code>_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7b15",
   "metadata": {},
   "source": [
    "#### 2- Missing data interpolation\n",
    "Fill the missing data using specified interpolation and <code>fill_nan()</code> methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.fill_nan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c870f",
   "metadata": {},
   "source": [
    "Once again lets ahe a look to the <code>correction_journal</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.correction_journal[\"fill_nan\"][\"missing_values\"][\"Percent_of_missing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf064",
   "metadata": {},
   "source": [
    "Wow, perfect dataset !\n",
    "\n",
    "Be careful 0 data missing doesn't mean 0 problem.\n",
    " If you had a crappy dataset, it is still crappy.\n",
    " You just filled the gaps by copying values or drawing lines between (_what seems to be_) valid points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3effa3",
   "metadata": {},
   "source": [
    "#### 3- Reducing dataset size\n",
    "As we said earlier 1min timestep is too small.\n",
    "Regarding the physical phenomenon involved here, we could say that 5min is ok.\n",
    "\n",
    "So lets resample the dataset to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.resample(\"5T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b142ebb",
   "metadata": {},
   "source": [
    "Let's have a look at our corrected data versus the raw data.\n",
    "\n",
    "We select a period around the gap we identified (from the 2018-03-24 to the 2018-03-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feafd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1'],\n",
    "    begin='2018-03-25 00:00:00',\n",
    "    end='2018-03-25 05:00:00',\n",
    "    plot_raw=True,\n",
    "    plot_corrected=True,\n",
    "    line_raw=False,\n",
    "    marker_corrected=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ab339",
   "metadata": {},
   "source": [
    "On the above graph you can see the effects of mean resampling, that diminishes the number of points and smooths out the data.\n",
    "\n",
    "The gap have been filled using linear interpolation at the required timestep.\n",
    "\n",
    "It is important to compare your data before and after applying the correction methods. For example, resampling with a large timestep can lead to a loss of information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
