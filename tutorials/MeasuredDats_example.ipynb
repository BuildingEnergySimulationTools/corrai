{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f8dc4",
   "metadata": {},
   "source": [
    "***Notebooks are written for Jupyter and might not display well in Github***\n",
    "\n",
    "\n",
    "# Loading and processing measured data with MeasuredDats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85508d",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to provide a comprehensive workflow for treating measured data using  **CorrAI** <code>MeasuredDats</code>.\n",
    "\n",
    "## Use case\n",
    "\n",
    "Measurements were collected from a real-scale benchmark conducted by Nobatek's BEF (Banc d'Essais Façade), which provides experimental cells for testing building façade solutions. Heat exchanges in a cell are limited to five of its faces, while the sixth face is dedicated to the tested solution. Internal temperature and hydrometry conditions can be controlled or monitored, and external conditions, such as temperatures and solar radiation, are measured.\n",
    "\n",
    "The experimental setup is presented in the following figures:\n",
    "\n",
    "| Figure 1: picture of the benchmark | Figure 2: wall layers from the inside (right) to the outside (left) |\n",
    "| :---: | :---: |\n",
    "|<img src=\"images/etics_pict.png\"  height=\"300\"> | <img src=\"images/etics_sch.png\"  height=\"300\"> |\n",
    "\n",
    "Additional details about the data:\n",
    "- The measurement campaign spanned from 07/06/2017 to 20/06/2017.\n",
    "- The acquisition timestep is probably 1 minute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768a5bb",
   "metadata": {},
   "source": [
    "# Measured data analysis and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bac0",
   "metadata": {},
   "source": [
    "Measured data are loaded using <code>pandas</code> python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    Path(r\"resources/tuto_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c929",
   "metadata": {},
   "source": [
    "Plotting the raw temperatures gives precious information on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc901bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['T_ext'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99064541",
   "metadata": {},
   "source": [
    "At first sight, a dataset may look fine, but missing values or incorrect variations are not always visible on a graph. The following steps are proposed to ensure data quality.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "- __upper__ and __lower vaues__  as boundaries. Measured values outside the interval are considered wrong\n",
    "- __upper__ and __lower \"rates__\". Measured value increasing beyond or below a defined threshold are considered wrong\n",
    "\n",
    "These boundaries are set depending on the measured physical phenomenon.\n",
    "For example, the boundaries for power and temperature will be configured differently.\n",
    "\n",
    "#### 2- Missing data interpolation\n",
    "Physical models do not tolerate missing values well. Therefore, for each sensor, we provide a method to interpolate missing data. We use a linear interpolation method to fill in the gaps between missing points. Errors at the beginning or end of the time series are filled with the first or last correct value.\n",
    "\n",
    "#### 3- Reducing dataset size\n",
    "Finally, a 1-minute acquisition timestep provides a heavy dataset.\n",
    "To make the dataset more manageable, we provide an aggregation method to _resample_ the dataset. Resampling allows the data to be aggregated into larger time intervals without losing critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae77f39",
   "metadata": {},
   "source": [
    "## Using MeasuredDat to perform operations on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466f8b9",
   "metadata": {},
   "source": [
    "The <code>MeasuredDats</code> **corrai** object is designed to specify transformations to apply to a measured dataset and to visualize their effects.\n",
    "The measured are classified in _categories_ (eg. temperature, power, control, etc.).\n",
    "There are 3 kinds of transformations :\n",
    "- _Category level_: specify transformations \"in parallel\" that will be applied to specified categories\n",
    "- _Common transformation_: apply transformation to all categories\n",
    "- _Resampling_: process data using a time rule and an aggregation method. It may be used to align data on a regular time index or reduce the size of the dataset\n",
    "\n",
    "<code>MeasuredDats</code> uses **Scikit Learn** _pipelines_. The transformers are <code>corrai.custom_transfomers</code> objects, they inherit from scikit base class <code>BaseEstimator</code> and <code>TransformerMixin</code>. These transformer ensure that Pandas <code>DataFrame</code> with <code>DateTimeIndex</code> are used through the process\n",
    "\n",
    "You can get the transformers keys using the function <code>corrai.measure.get_transformers_keys()</code>\n",
    "\n",
    "Refer to <code>corrai.custom_transformers</code> documentation to configure transformers arguments.\n",
    "\n",
    "The figure below describes a \"pipeline\" that apply a series of corrections to the dataset.\n",
    "\n",
    "<img src=\"images/pipe.png\"  height=\"300\">\n",
    "\n",
    "4 successive transformations are applied: 2 category transformations, a common transformation and a resampling operation.\n",
    "\n",
    "The **categories** are specified using <code>data_type_dict</code> :\n",
    "```\n",
    "category_dict = {\n",
    "    \"Temperatures\": [\"temp_1\", \"temp_2\"],\n",
    "    \"Power\": [\"pow_1\"],\n",
    "    \"radiation\": [\"Sol_rad\"]\n",
    "    }\n",
    "```\n",
    "\n",
    "The **category transformations** are specified using <code>category_transformations</code> :\n",
    "```\n",
    "category_transformations = {\n",
    "    \"Temperatures\":{\n",
    "        \"ANOMALIES\": [\n",
    "            [\"drop_threshold\", {\"upper\": 40000, \"lower\": 0}],\n",
    "            [\"drop_time_gradient\", {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "    },\n",
    "    \"Power\": {\n",
    "        \"ANOMALIES\": [\n",
    "            [\"drop_threshold\", {\"upper\": 50, \"lower\": -2}],\n",
    "            [\"drop_time_gradient\", {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "        \"PROCESS\": [\n",
    "            [\"apply_expression\", {\"expression\": \"x / 1000\"}]\n",
    "        ],\n",
    "    },\n",
    "    \"radiation\": {}\n",
    "},\n",
    "```\n",
    "\n",
    "- The dictionary keys must match the category defined in <code>category_dict</code>\n",
    "- For each category you can specify as much transformer as you want. Similar name must be given in each category if you want transformer to be used in the same _\"category transformation\"_ (eg. ANOMALIES)\n",
    "- For each transformer a list of transformation is given. They are defined by a list with two elements [custom_transformer key, {custom transformer args}]\n",
    "- If the category doesn't require any transformation, specify an empty dictionary\n",
    "\n",
    "The **common transformations** are specified using <code>common_transformations</code>:\n",
    "\n",
    "```\n",
    "common_transformations={\n",
    "    \"COMMON\": [\n",
    "        [\"interpolate\", {\"method\": 'linear'}],\n",
    "        [\"fill_na\", {\"method\": 'bfill'}]\n",
    "    ]\n",
    "}\n",
    "```\n",
    "- The dictionary keys are the names of the common transformers\n",
    "- For each transformer, a list of transformations is given. They are defined by a list of two elements [custom_transformer key, {custom transformer args}]\n",
    "\n",
    "The **Resampler** is configured :\n",
    "```\n",
    "resampler_agg_methods={\n",
    "    \"Temperatures\": \"mean\"\n",
    "}\n",
    "```\n",
    "\n",
    "- An optional key \"RESAMPLE\" may be given to specify the category aggregation method in case of resampling. By default, resampling method is mean. If you want \"mean\" for all categories, an empty dictionary may be specified (default value)\n",
    "\n",
    "\n",
    "The **transformer list** :\n",
    "Lastly you can specify the order of the transformations using <code>transformers_list</code>. For example <code>transformers_list = [\"ANOMALIES\", \"COMMON\", \"RESAMPLER\", \"PROCESS\"]</code>.\n",
    "- If <code>transformer_list</code> is left to <code>None</code>, transformers list hold all the category_transformers, than all the common transformers\n",
    "- If <code>\"RESAMPLER\"</code> is not present in <code>transformer_list</code>, but a <code>resampling_rule</code> is provided, the <code>\"RESAMPLER\"</code> will automatically be added at the end of the <code>transformers_list</code>.\n",
    "- This list can be changed at all time.\n",
    "- You don't have to use all the transformers,\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "6256a228",
   "metadata": {},
   "source": [
    "Here is an example for the dataset we just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.measure import MeasuredDats\n",
    "from corrai.measure import get_transformers_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f28fed",
   "metadata": {},
   "source": [
    "The function <code>get_transformers_keys()</code> is designed to print the available transformers names and help you configure <code>MeasuredDats</code>. More information on these transformers are available in the <code>corrai.custom_transformers.py</code> script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transformers_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MeasuredDats(\n",
    "    data = raw_data,\n",
    "    category_dict = {\n",
    "        \"temperatures\": [\n",
    "            'T_Wall_Ins_1', 'T_Wall_Ins_2', 'T_Ins_Ins_1', 'T_Ins_Ins_2',\n",
    "            'T_Ins_Coat_1', 'T_Ins_Coat_2', 'T_int_1', 'T_int_2', 'T_ext', 'T_garde'\n",
    "        ],\n",
    "        \"illuminance\": [\"Lux_CW\"],\n",
    "        \"radiation\": [\"Sol_rad\"]\n",
    "    },\n",
    "    category_transformations = {\n",
    "        \"temperatures\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 100, \"lower\": -20}],\n",
    "                [\"drop_time_gradient\", {\"upper_rate\": 2, \"lower_rate\": 0}]\n",
    "            ],\n",
    "        },\n",
    "        \"illuminance\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "        },\n",
    "        \"radiation\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [\"drop_threshold\", {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    common_transformations={\n",
    "        \"COMMON\": [\n",
    "            [\"interpolate\", {\"method\": 'linear'}],\n",
    "            [\"fill_na\", {\"method\": 'bfill'}],\n",
    "        ]\n",
    "    },\n",
    "    transformers_list=[\"ANOMALIES\", \"COMMON\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee27fd",
   "metadata": {},
   "source": [
    "Note that <code>transformers_list</code> could have been left to None. Here, we are applying the _anomalies_ transformer, then the _common_ transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54297b",
   "metadata": {},
   "source": [
    "The <code>plot</code> method can be used to plot the data.\n",
    "\n",
    "Provide a <code>list</code> to the argument <code>cols</code> to specify the entries you want to plot. A new y axis will be created for each data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac115e7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-04-15',\n",
    "    end='2018-04-18',\n",
    "    title='Plot uncorrected data',\n",
    "    marker_raw=True,\n",
    "    line_raw=False,\n",
    "    plot_raw = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e79b06",
   "metadata": {},
   "source": [
    "Plotted data are the <code>corrected_data</code> obtained after going through the pipeline described in the <code>MeasuredDats</code> object's <code>transformers_list</code>. You can specify an alternative transformers_list using the <code>plot</code> function argument <code>transformers_list</code>.\n",
    "\n",
    "Use <code>plot_raw=True</code> to display raw data. This is useful to assess the impact of the correction and of the resampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3932",
   "metadata": {},
   "source": [
    "\n",
    "The <code>get_missing_values_stats</code> method gives information on the amount of missing values.\n",
    "You can get it for raw, corrected or partially corrected data depending on the transformers specified in <code>transformers_list</code>.\n",
    "\n",
    "Let's have a look for raw data. We specify an empty <code>transformers_list</code> that create a pipeline with a single Identity transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4db7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats(transformers_list=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb603",
   "metadata": {},
   "source": [
    "Before correction, the journal shows that ~2% of the data is missing for the temperature sensor and ~3% for external temperature, \"garde\" temperature and solar radiation. It corresponds to data having a timestamp, but with missing value. In this specific case, this is not related to sensors errors. 2 distinct acquisition device were used to perform the measurement. The merging of the data from the two devices created troubles in timestamp \"alignment\". Also measurement stopped a bit earlier for the second device.\n",
    "\n",
    "#### 1- Identification of anomalies:\n",
    "Now let's apply the ANOMALIES transformer to delete invalid data according to the specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386abd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats([\"ANOMALIES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd878",
   "metadata": {},
   "source": [
    "It looks like the applied corrections removed several data.\n",
    "For example, the sensors measuring the cell internal temperature have now up to __4.7%__ of missing data.\n",
    "\n",
    "Few corrections were applied to the outside temperature sensor.\n",
    "\n",
    "The journal of correction holds further information on the gaps of data.\n",
    "For example, we might want to know more about the missing values of <code>T_int_1</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_gaps_description(cols=[\"T_int_1\"], transformers_list=[\"ANOMALIES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3f59",
   "metadata": {},
   "source": [
    "- There are 11220 gaps\n",
    "- 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The longest is 1h\n",
    "\n",
    "It is also possible to \"aggregate\" the gaps to know when at least one of the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_gaps_description(transformers_list=[\"ANOMALIES\"])[\"combination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c767b8",
   "metadata": {},
   "source": [
    "- There are 28007 gaps (~10% of the dataset).\n",
    "- The size of 75% of these gaps do not exceed 2 minutes\n",
    "- The biggest gap lasts about 1 hour\n",
    "\n",
    "There is not a lot of difference. It looks like the values are missing at the same timestamps. This is good news, it means that there are a lot of periods with all data available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275e599",
   "metadata": {},
   "source": [
    "The plotting method <code>plot_gaps</code> can be used to visualize where the gap(s) happened.\n",
    "\n",
    "This dataset holds a lot of values, hence we only plot the input <code>'T_int_1'</code> here, as it is supposed to have the more gaps.\n",
    "\n",
    "We are interested in gaps lasting more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88573e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "my_data.plot_gaps(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-03-25',\n",
    "    end='2018-03-25',\n",
    "    gaps_timestep=dt.timedelta(minutes=15),\n",
    "    transformers_list=[\"ANOMALIES\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f229b95",
   "metadata": {},
   "source": [
    "There seem to be only 1 gap greater than 15 minutes, it happens the 2018-03-25 between ~02:00 and ~3:00.\n",
    "This is the gap we identified in the correction journal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7b15",
   "metadata": {},
   "source": [
    "#### 2- Missing data interpolation\n",
    "In our example, the same method is used to fill the gaps for all categories.\n",
    "It is described in <code>common_transformations</code>\n",
    "Below is the object transformers list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.transformers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799dc35",
   "metadata": {},
   "source": [
    "To get the corrected data, we just need to call <code>get_corrected_data</code> method, with default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_corrected_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c870f",
   "metadata": {},
   "source": [
    "We can check the effect of the transformation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf064",
   "metadata": {},
   "source": [
    "Wow, perfect dataset !\n",
    "\n",
    "**Be careful** 0 missing data doesn't mean 0 problem.\n",
    " If you had a crappy dataset, it is still crappy.\n",
    " You just filled the gaps by copying values or drawing lines between (_what seems to be_) valid points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3effa3",
   "metadata": {},
   "source": [
    "#### 3- Reducing the dataset size\n",
    "As we noted earlier, 1min timestep is too small.\n",
    "Regarding the physical phenomenon involved here, we could say that 5min is ok.\n",
    "Let's have a look at the corrected data versus the raw data.\n",
    "We select a period around the gap we identified (from the 2018-03-24 to the 2018-03-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feafd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1'],\n",
    "    begin='2018-03-25 00:00:00',\n",
    "    end='2018-03-25 05:00:00',\n",
    "    plot_raw=True,\n",
    "    plot_corrected=True,\n",
    "    line_raw=False,\n",
    "    marker_corrected=True,\n",
    "    resampling_rule='5T'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ab339",
   "metadata": {},
   "source": [
    "On the above graph, you can see the effects of mean resampling, that diminishes the number of points and smooths out the data.\n",
    "\n",
    "The gap have been filled out, using linear interpolation at the required timestep.\n",
    "\n",
    "It is important to compare your data before and after applying the correction methods. For example, resampling with a large timestep can lead to a loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd72853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
