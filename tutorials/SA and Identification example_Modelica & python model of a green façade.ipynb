{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This tutorial can be found and ran in the GITHUB libray corrAI: https://github.com/BuildingEnergySimulationTools/corrai",
   "id": "fe658bc78054a398"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Characterisation method tutorial"
   ],
   "id": "d62323ea2b70844"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The aim of this tutorial is to provide a complete workflow for material physical properties identification of a reference wall using **Modelitool** (modelica simulator) and **CorrAI** models by following these steps:\n",
    "\n",
    "1. **Measurement import and verification**:\n",
    "    - We will import measurement dataframe into the notebook and check measurement before selecting an analysis period.\n",
    "    \n",
    "2. **Model creation/import**:\n",
    "    - We will either create a new mathematical model or impor model (FMU, openModelica).\n",
    "\n",
    "3. **Performing sensitivity analysis**:\n",
    "    - Sensitivity analysis will be conducted to determine how different input variables affect the output of the model. This step helps in identifying the most influential parameters in the model.\n",
    "\n",
    "4. **Model identification**:\n",
    "    - Using the results from the sensitivity analysis, we will identify the parameters that need to be adjusted to improve the model's accuracy. This involves fitting the model to the data and refining its parameters.\n",
    "\n",
    "---"
   ],
   "id": "fc9dbe513aaef7ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "4ed710c97edd95e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Use case presentation\n",
    "\n",
    "A \"real-scale\" test bench is used. The **O3BET** (or in this example BEF test bench in Anglet, France) offers experimental conditions to evaluate building façade solutions. Heat exchanges in a cell are restricted on five of its faces, while the sixth face is dedicated to the tested solution. Internal temperature and humidity conditions can be controlled or monitored. External conditions, including temperatures and solar radiation, are measured.\n",
    "\n",
    "The tested technology here is a green façade, coupled wiht insulated panels. The experimental setup is presented in the following picture: one cell is equiped with the technology (right one) and another serves as a reference (insulation only).\n",
    "\n",
    "| Figure : Pictures of reference wall and Urban Canopee installation |\n",
    "| :---: |\n",
    "| <img src=\"images/cladding.png\"  style=\"height:200px;\">  <img src=\"images/BEF_facades.jpeg\"  style=\"height:200px;\"> |\n",
    "\n",
    "Sensors (heatflux density meters, thermocouples, RTD) are positioned in several parts: in the middle of insulation panels, between insulation and concrete layers, between leaves, in substrates, indoor. Climatic conditions (external temperature, incident solar radiation) are also monitored.\n",
    "\n",
    "\n",
    "| Figure : Sensors installation scheme |\n",
    "| :---: |\n",
    "| <img src=\"images/sensors.png\"  style=\"height:200px;\">  <img src=\"images/Sensor_photo1.jpeg\"  style=\"height:200px;\"> <img src=\"images/Sensor_photo2.jpeg\"  style=\"height:200px;\">   | \n",
    "\n",
    "- Measure campaign spans from  april 2024 to october 2024\n",
    "- Acquisition timestep is 60 secondes minimum."
   ],
   "id": "49fdc09f8bf34966"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Identification framework\n",
    "The following framework is proposed to identify the **REFERENCE** wall thermal conductivity, and provides:\n",
    "- Physical model description using Python\n",
    "- Sensitivity analysis to identify materials properties which have an influence on the discrepancy between model outputs and measured phenomenon\n",
    "- Wall thermal conductivity identification using optimization algorithm"
   ],
   "id": "eb68fb42d92f1785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Measurement import and verification\n",
    "\n",
    "First, let's load some generic libraries (pandas, Path). We can also define the function datetime_to_seconds, which will be later used to convert datetimes to seconds.\n",
    "\n",
    "\n",
    "Then we can load the reference cell measurement data on python that will be used as boundary conditions. Note that the data loaded here should be cleaned beforhand (see Tutorial **\"MeasuredDat example\"** if needed)"
   ],
   "id": "cad4938a77f4a783"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ],
   "id": "77c679d36151b736",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime as dt\n",
    "\n",
    "def datetime_to_seconds(index_datetime):\n",
    "    time_start = dt.datetime(index_datetime[0].year, 1, 1, tzinfo=dt.timezone.utc)\n",
    "    new_index = index_datetime.to_frame().diff().squeeze()\n",
    "    new_index.iloc[0] = dt.timedelta(\n",
    "        seconds=index_datetime[0].timestamp() - time_start.timestamp()\n",
    "    )\n",
    "    sec_dt = [elmt.total_seconds() for elmt in new_index]\n",
    "    return list(pd.Series(sec_dt).cumsum())"
   ],
   "id": "2f8d425878b94320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "TUTORIAL_DIR = Path(os.getcwd()).as_posix()",
   "id": "59473d207b322155",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reference_df = pd.read_csv(\n",
    "    Path(TUTORIAL_DIR) / \"resources/tuto_data_SA.csv\",\n",
    "    index_col=0,\n",
    "    sep=\";\",\n",
    "    decimal=\".\",\n",
    "    parse_dates=True\n",
    ")"
   ],
   "id": "6d01322236314e2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reference_df.head()",
   "id": "8a81862b0c17b1b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reference_df.isna().any().any()",
   "id": "5a3e4bb69c962f76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There seems to be no missing data. Let's first plot all data to check if nothing stands out. Although data was cleaned (supposedly, some measurement errors and irregularities might have been missed in the process.",
   "id": "3da1cce8d7320cb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.line(reference_df)",
   "id": "bed89b439bf7437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we can see that one of the temperature sensors installed in the insulation panels stopped measuring on september 7th. Only T_ins_2 will be used as the insulation temperature.",
   "id": "c579c990290e894c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reference_df.loc[:,\"T_ins\"] = reference_df['T_ins_2'] # middle of insulation temperature\n",
    "reference_df.loc[:,\"T_int\"] =reference_df[['Tint_1', 'Tint_2']].mean(axis=1) # indoor temperature\n",
    "reference_df.loc[:,\"T_interface\"] =  reference_df[['T_interface_1', 'T_interface_2']].mean(axis=1) # interface temperature, between insulation and concrete panels"
   ],
   "id": "b84fb1e0db1d3855",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For modeling purpose, we convert the temperature from °C to Kelvin.",
   "id": "afb9340941fec786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temperatures = [\n",
    "    'T_ins',\n",
    "    'T_int',\n",
    "    'T_interface', \n",
    "    'T_ext'\n",
    "]\n",
    "reference_df[temperatures] += 273.15"
   ],
   "id": "d29a52e89115cdd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Also, for the first simulation, let's chose a short period with both sunny and cloudy days:",
   "id": "6b4ea7c50fac69a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulation_df = reference_df.loc[\"2024-09-04 00:00\":\"2024-09-09 00:00\"]",
   "id": "342da2f0046b008a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Modeling approach and set-up",
   "id": "ac2b9b75817d9ed5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Proposed model ",
   "id": "8848934ec278aa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For this example we propose a resistance/capacity approach. Based on electrical circuit analogy, each layer of the wall is modeled by two resistances and a capacity:\n",
    "\n",
    "\n",
    "| Figure : RC model|\n",
    "| :---: |\n",
    "| <img src=\"images/RC_model.png\"  style=\"height:400px;\">   | \n",
    "\n",
    "\n",
    "Note that it is recommended to start with a **very simple** model (e.g., one resistance, one capacity with only Text and Tint as boundary conditions) and gradually make it more complex as you identify parameters. For the sake of this tutorial, the proposed model is already a bit detailed.\n",
    "\n",
    "\n",
    "The following is a brief description of the thermal model:\n",
    "\n",
    "- Each wall layer is modeled by 2 thermal resistances and a capacity.\n",
    "    - Resistances to create a gradiant and better resolution of distribution of heat flow : $ R_1 = R_2 = \\frac{ep_{layer}}{lambda_{layer} \\times 2} $ \n",
    "    - Capacity in the middle of both our layers, representing its thermal mass and ability to store heat. : $ C = ep_{layer} \\times rho_{layer} \\times cap_{layer} $\n",
    " \n",
    "- Inside and outside convection/conduction transfers are model as a constant value thermal resistance.\n",
    "\n",
    "- Infrared transfers are considered :\n",
    "    - With the sky, with $ T_{sky} = 0.0552T_{ext}^{1.5} $ as the sky is a significant source of infrared radiation, especially at night. This radiation can have a considerable impact on the thermal behavior of the system, influencing both heating and cooling processes\n",
    "    - With the surrounding considered to be at $ T_{ext} $ as surroundings or environment also emit infrared radiation\n",
    "\n",
    "- Short wave solar radiation heat flux is computed $Sw_{gain} = Pyr \\times \\alpha_{coat} $ with $Pyr$ the measured solar radiation onthe wall (W/m²) and  $\\alpha_{coat}$ the coating solar absorbtion coefficient.\n",
    "\n",
    "- Temperatures $ T_{ext}$ and $T_{int} $ are boundary conditions.  $ T_{int}$ represents the temperature within the controlled environment of the system.\n",
    "\n",
    "Here are somes theoretical parameters for the model:"
   ],
   "id": "be34c58477a92f22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Surface of the tested wall\n",
    "S_wall =  7\n",
    "\n",
    "# Thickness of layer\n",
    "ep_concrete = 0.200 #m\n",
    "ep_ins = 0.140 #m\n",
    "\n",
    "# Conductivity of layer\n",
    "lambda_concrete = 0.13 # (W/mK)\n",
    "lambda_ins = 0.031 # W/(mK)\n",
    "\n",
    "# Density of layer\n",
    "rho_concrete = 2400 # kg/m3 \n",
    "rho_ins = 32.5  # kg/m3\"\n",
    "\n",
    "\n",
    "sc_concrete = 880 # J/kg.K\n",
    "sc_ins = 1000 # J/kg.K\n",
    "\n",
    "# solar paremetesr\n",
    "alpha = 0.2 # absorption coefficient\n",
    "epsilon = 0.8 # emissivity \n",
    "fview = 0.5 # view factor of tested wall"
   ],
   "id": "536c528c698d62a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Define a simulator\n",
    "\n",
    "You can either load a Modelica model or FMU (using **Modelitool** library, see: https://github.com/BuildingEnergySimulationTools/modelitool), \n",
    "or directly write a model on Python. For either, here are some in common parameters definition. \n",
    "\n",
    "For the model to work with corrAI and modelitool libraries (sensitivity analyses, optimisation, etc.), the model will be written as a class with :\n",
    "- A parameter dictionary,\n",
    "- Simulation options.\n",
    "\n",
    "How does it work:\n",
    "\n",
    "- Parameters: The wall's thermal resistances (R_ext, R_int, R_concrete, R_ins) and heat capacities (C_concrete, C_ins) are initialized with default values, but can be overridden by user inputs. Other physical parameters include the wall surface area (S_wall), view factor (fview), and material emissivity (epsilon).\n",
    "- Dataframe: The model uses a dataframe input which includes external and internal temperatures (T_ext, T_int), time (time_sec), and solar radiation (Pyr from a pyranometer).\n",
    "- Initial Conditions: The temperatures of the external surface, concrete, insulation, and interfaces are initialized based on the external and internal temperatures at the start.\n",
    "- Time-Stepping: The simulation proceeds over time steps, updating temperatures at each layer.\n",
    "- Radiative Heat Transfer: The model calculates radiative heat transfer between the wall surface and the sky, ambient, and direct solar radiation.\n",
    "- Temperature Update: At each time step, temperatures are updated based on thermal resistances and capacitances of each layer using a finite difference approach."
   ],
   "id": "fa7b692f2ef788f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from corrai.base.model import Model\n",
    "\n",
    "class OpaqueWallSimple(Model):\n",
    "    def simulate(\n",
    "        self,\n",
    "        property_dict: dict,\n",
    "        simulation_options: dict,\n",
    "        simulation_kwargs: dict | None = None,\n",
    "        **kwargs,\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        default_parameters = {\n",
    "            \"R_ext\": 0.005,\n",
    "            \"R_int\": 0.01,\n",
    "            \"R_concrete\": 0.10,\n",
    "            \"R_ins\": 0.32,\n",
    "            \"C_concrete\": 2.95e6,\n",
    "            \"C_ins\": 3.64e4,\n",
    "            \"alpha\": 0.2,\n",
    "            \"S_wall\": 7,\n",
    "            \"epsilon\": 0.4,\n",
    "            \"fview\": 0.5,\n",
    "        }\n",
    "        parameters = {**default_parameters, **property_dict}\n",
    "\n",
    "        R_ext       = parameters[\"R_ext\"]\n",
    "        R_int       = parameters[\"R_int\"]\n",
    "        R_concrete  = parameters[\"R_concrete\"]\n",
    "        R_ins       = parameters[\"R_ins\"]\n",
    "        C_concrete  = parameters[\"C_concrete\"]\n",
    "        C_ins       = parameters[\"C_ins\"]\n",
    "        alpha       = parameters[\"alpha\"]\n",
    "        S_wall      = parameters[\"S_wall\"]\n",
    "        epsilon     = parameters[\"epsilon\"]\n",
    "        fview       = parameters[\"fview\"]\n",
    "\n",
    "        sigma = 5.67e-8  # W/m^2/K^4\n",
    "\n",
    "        df = simulation_options[\"dataframe\"]\n",
    "        time  = df[\"time_sec\"].values\n",
    "        T_ext = df[\"T_ext\"].values\n",
    "        T_int = df[\"T_int\"].values\n",
    "        Q_rad = df[\"Pyr\"].values\n",
    "\n",
    "        startTime = simulation_options.get(\"startTime\", time[0])\n",
    "        stopTime  = simulation_options.get(\"stopTime\",  time[-1])\n",
    "\n",
    "        mask  = (time >= startTime) & (time <= stopTime)\n",
    "        time  = time[mask]\n",
    "        T_ext = T_ext[mask]\n",
    "        T_int = T_int[mask]\n",
    "        Q_rad = Q_rad[mask]\n",
    "\n",
    "        # init\n",
    "        T_se        = np.zeros(len(time))\n",
    "        T_concrete  = np.zeros(len(time))\n",
    "        T_ins       = np.zeros(len(time))\n",
    "        T_interface = np.zeros(len(time))\n",
    "        T_si        = np.zeros(len(time))\n",
    "        T_sky       = np.zeros(len(time))\n",
    "\n",
    "        T_se[0]        = T_ext[0]\n",
    "        T_concrete[0]  = 299\n",
    "        T_ins[0]       = T_int[0]\n",
    "        T_interface[0] = (T_ins[0] + T_concrete[0]) / 2\n",
    "        T_si[0]        = T_int[0]\n",
    "        T_sky[0]       = T_int[0]\n",
    "\n",
    "        for t in range(1, len(time)):\n",
    "            dt = time[t] - time[t - 1]\n",
    "\n",
    "            T_sky[t] = 0.0552 * (T_ext[t] ** 1.5)\n",
    "\n",
    "            Q_rad_sky = epsilon * fview * sigma * (T_se[t - 1] ** 4 - T_sky[t] ** 4) * S_wall\n",
    "            Q_rad_amb = epsilon * fview * sigma * (T_se[t - 1] ** 4 - T_ext[t - 1] ** 4) * S_wall\n",
    "            Q_rad_dir = Q_rad[t - 1] * alpha * S_wall\n",
    "\n",
    "            T_se[t] = (\n",
    "                T_ext[t - 1] / R_ext\n",
    "                + T_ins[t - 1] / (R_ins / 2)\n",
    "                + Q_rad_dir - Q_rad_sky - Q_rad_amb\n",
    "            ) / (1 / R_ext + 1 / (R_ins / 2))\n",
    "\n",
    "            T_interface[t] = (\n",
    "                T_ins[t - 1] / (R_ins / 2) + T_concrete[t - 1] / (R_concrete / 2)\n",
    "            ) / (1 / (R_concrete / 2) + 1 / (R_ins / 2))\n",
    "\n",
    "            T_si[t] = (\n",
    "                T_int[t - 1] / R_int + T_concrete[t - 1] / (R_concrete / 2)\n",
    "            ) / (1 / R_int + 1 / (R_concrete / 2))\n",
    "\n",
    "            T_ins[t] = T_ins[t - 1] + dt / C_ins * (\n",
    "                (T_se[t] - T_ins[t - 1]) / (R_ins / 2)\n",
    "                + (T_interface[t] - T_ins[t - 1]) / (R_ins / 2)\n",
    "            )\n",
    "\n",
    "            T_concrete[t] = T_concrete[t - 1] + dt / C_concrete * (\n",
    "                (T_interface[t] - T_concrete[t - 1]) / (R_concrete / 2)\n",
    "                + (T_si[t] - T_concrete[t - 1]) / (R_concrete / 2)\n",
    "            )\n",
    "\n",
    "        # output\n",
    "        df_out = pd.DataFrame(\n",
    "            {\n",
    "                \"T_concrete\":  T_concrete,\n",
    "                \"T_interface\": T_interface,\n",
    "                \"T_ins\":       T_ins,\n",
    "            },\n",
    "            index=df.index[mask],\n",
    "        )\n",
    "        self.simulation_options = simulation_options\n",
    "        return df_out"
   ],
   "id": "ce77813f073f7e13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Datetime should be in second: we can use datetime_to_seconds function defined earlier. Moreover, data are in minutes, we should resample them to 5min samples.",
   "id": "49afd017d15ef580"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulation_df.loc[:,\"time_sec\"] = datetime_to_seconds(simulation_df.index)\n",
    "simulation_df_resample = simulation_df.resample(\"5min\").mean()"
   ],
   "id": "81614ca843787295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, let's define: \n",
    "- simulation options, with starttime, endtime, and a dataframe for boundary conditions\n",
    "- a dictionary, containing values for ou different parameters"
   ],
   "id": "946f30e15c17a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "second_index = datetime_to_seconds(simulation_df_resample.index)",
   "id": "c4af9c61d72ec5cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulation_options_PYTH={\n",
    "    \"dataframe\":simulation_df_resample,\n",
    "    \"startTime\": second_index[0],\n",
    "    \"endTime\": second_index[-1],  \n",
    "}"
   ],
   "id": "71b2a7cf44a5deb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameter_dict_PYTH = {\n",
    "    \"R_ext\": 0.04/S_wall,       \n",
    "    \"R_int\": 0.13/S_wall,      \n",
    "    \"R_concrete\": 1 / (lambda_concrete / ep_concrete) / 2 / S_wall,   \n",
    "    \"R_ins\": 1 / (lambda_ins / ep_ins) / 2 / S_wall, \n",
    "    \"C_ins\": rho_ins*ep_ins*S_wall*sc_ins,  \n",
    "    \"C_concrete\": rho_concrete*ep_concrete*S_wall*sc_concrete,       \n",
    "    \"alpha\": alpha,       \n",
    "    \"S_wall\": S_wall,         \n",
    "    \"epsilon\": epsilon,\n",
    "    'fview': fview\n",
    "}"
   ],
   "id": "58ae79a228160f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now instantiate the model and run the simulation. ",
   "id": "db06964b679af24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simu_PYTH = OpaqueWallSimple()\n",
    "\n",
    "init_res_PYTH = simu_PYTH.simulate(\n",
    "    property_dict=parameter_dict_PYTH,\n",
    "    simulation_options=simulation_options_PYTH\n",
    ")"
   ],
   "id": "34845fea7fc10aad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "init_res_PYTH.head()",
   "id": "549136e8960dc769",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's compare results to measurement:",
   "id": "8e2d5abe27a2cf9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#renaming\n",
    "copy_res = init_res_PYTH\n",
    "copy_res.index = copy_res.index.tz_localize(None)\n",
    "\n",
    "copy_res = copy_res.rename(columns={\n",
    "    \"T_concrete\": \"T_concrete_PYTHON\",\n",
    "    \"T_interface\": \"T_interface_PYTHON\",\n",
    "    \"T_ins\": \"T_insulation_PYTHON\",\n",
    "})"
   ],
   "id": "4d225f8a2dcdd2b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "measure_comp = pd.concat([\n",
    "    simulation_df_resample[[\"T_interface\", \"T_ins\"]], \n",
    "    copy_res[[\"T_interface_PYTHON\", \"T_insulation_PYTHON\" ]]], axis = 1)\n",
    "\n",
    "color_map = {\n",
    "    \"T_interface\": \"darkblue\", \n",
    "    \"T_interface_PYTHON\": \"blue\", \n",
    "    \"T_ins\": \"darkgreen\", \n",
    "    \"T_insulation_PYTHON\": \"green\" \n",
    "}\n",
    "\n",
    "fig = px.line(measure_comp)\n",
    "\n",
    "for trace in fig.data:\n",
    "    trace_name = trace.name\n",
    "    if trace_name in color_map:\n",
    "        trace.line.color = color_map[trace_name]\n",
    "        \n",
    "fig.show()"
   ],
   "id": "374575bc5edf48b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Not  good. A sensitivity analysis should be performed to rank the parameters by order of influence on the error between measured temperature and model prediction.\n",
   "id": "ec5e69a99a60a6dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Sensitivity analysis\n",
    "It is very important to know how our defined parameters have an influence on the model prediction. Therefore, we use a sensitivity analysis to \"rank\" the parameter by order of influence\n",
    "on the model error. "
   ],
   "id": "ccdfb5cca982ee18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.1. Error function\n",
    "The chosen error function is the CV_RMSE. The formula for CV_RMSE is given by:\n",
    "\n",
    "$$\n",
    "CV\\_RMSE = \\frac{RMSE}{\\bar{y}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- *RMSE* is the root mean squared error,\n",
    "- *bar{y}* is the mean of the observed values.\n",
    "\n",
    "The RMSE is calculated as:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- *n* is the number of observations,\n",
    "- *y_i* is the observed value for the \\( i \\)-th observation,\n",
    "- *hat{y}_i* is the predicted value for the \\( i \\)-th observation.\n",
    "\n",
    "The CV_RMSE measures the variation of the RMSE relative to the mean of the observed values. It provides a standardized measure of the error, which can be useful for comparing the performance of different models across different datasets.\n",
    "Here, we can chose the error function as the CV_RMSE between measured temperature(s) and model prediction."
   ],
   "id": "e46bcafc7717aa5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2. Tested parameters\n",
    "\n",
    "The chosen parameters are all the model parameters θ=(R_concrete, R_ins, C_ins, C_concrete, alpha, epsilon, R_ext, R_int ).\n",
    "Each decision variable of the optimization problem must be described using a `Parameter` object.\n",
    "A parameter specifies:\n",
    "* `name` — The variable name (string, must be unique within the problem).\n",
    "* `ptype` — Variable type, one of:\n",
    "    * `\"Real\" `— Continuous real number\n",
    "    * `\"Integer\"` — Discrete integer\n",
    "    * `\"Binary\"` — Boolean, domain {False, True} (set automatically if no domain is given)\n",
    "    *` \"Choice\"` — Categorical variable with a fixed set of discrete options\n",
    "* `Domain definition` — Choose exactly one of:\n",
    "    * ` interval=(lo, hi) `— Lower and upper bounds (for \"Real\" and \"Integer\", optional for \"Binary\" if you want (0,1))\n",
    "    * ` values=(v1, v2, …)` — Explicit list/tuple of allowed values (for \"Choice\", and optionally for \"Integer\", \"Real\", or \"Binary\")\n",
    "*` Optional fields`:\n",
    "    * `init_value` — Initial value (or tuple/list of initial values for batch runs); must be within the defined domain\n",
    "    * `relabs` — `\"Absolute\"` or `\"Relative\"` (or a boolean flag, depending on usage in your model)\n",
    "    * `model_property` — String or tuple specifying the corresponding property in the simulation/model\n",
    "    * `min_max_interval` — Optional extra bounds for use in analysis/validation"
   ],
   "id": "da0b289ff76e21de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from corrai.base.parameter import Parameter",
   "id": "ea7f3dc574b396f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frac_p = 0.20 # 20%\n",
    "frac_conv = 0.40 # 40%\n",
    "\n",
    "params = [\n",
    "    Parameter(\n",
    "        name='R_concrete',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        ptype=\"Real\",\n",
    "        init_value=1 / (lambda_concrete / ep_concrete) / 2 / S_wall,\n",
    "        relabs=\"Relative\",\n",
    "        model_property='R_concrete',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='R_ins',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        init_value=1 / (lambda_ins / ep_ins) / 2 / S_wall,\n",
    "        relabs=\"Relative\",\n",
    "        ptype=\"Real\",\n",
    "        model_property='R_ins',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='C_ins',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        init_value=rho_ins*ep_ins*S_wall*sc_ins,\n",
    "        relabs=\"Relative\",\n",
    "        ptype=\"Real\",\n",
    "        model_property='C_ins',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='C_concrete',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        init_value=rho_concrete*ep_concrete*S_wall*sc_concrete,\n",
    "        relabs=\"Relative\",\n",
    "        ptype=\"Real\",\n",
    "        model_property='C_concrete',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='alpha',\n",
    "        interval=(0.1, 0.6),\n",
    "        ptype=\"Real\",\n",
    "        model_property='alpha',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='epsilon',\n",
    "        interval=(0.2, 0.9),\n",
    "        ptype=\"Real\",\n",
    "        model_property='epsilon',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='R_ext',\n",
    "        init_value= 0.04/S_wall,\n",
    "        interval=(1-frac_conv, 1+frac_conv),\n",
    "        ptype=\"Real\",\n",
    "        relabs=\"Relative\",\n",
    "        model_property='R_ext',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='R_int',\n",
    "        init_value= 0.13/S_wall,\n",
    "        interval=(1-frac_conv, 1+frac_conv),\n",
    "        ptype=\"Real\",\n",
    "        relabs=\"Relative\",\n",
    "        model_property='R_int',\n",
    "    ),\n",
    "]"
   ],
   "id": "8f8e2bab5b874374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3. Problem description\n",
    "We can now load from `corrai.sensitivity` module a sensitivity method.\n",
    "\n",
    "*Note: for now, only <code>SOBOL</code>, <code>FAST</code>, <code>RBD_FAST</code>, \n",
    "and <code>MORRIS</code> methods are implemented.*"
   ],
   "id": "64dfc055e9c59627"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1.A SOBOL method",
   "id": "3c70d720457ec5a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from corrai.sensitivity import SobolSanalysis",
   "id": "f8e6cd080e0732af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sa_study = SobolSanalysis(\n",
    "    parameters=params,\n",
    "    model=simu_PYTH,\n",
    "    simulation_options=simulation_options_PYTH,\n",
    ")"
   ],
   "id": "cba431b6fc562b4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The method add sample draw a sample of parameters to be simulated. Each method has its sampling method. Please see SALib documentation for further explanation (https://salib.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "Note that:\n",
    "- Convergence properties of the Sobol' sequence is only valid if\n",
    "        `N` (100) is equal to `2^n`.\n",
    "        N (int) – The number of samples to generate. Ideally a power of 2 and <= skip_values.\n",
    "- Convergence properties of the Fast' method is only valid if sample size N > 4M^2 (M=4 by default)"
   ],
   "id": "2c00547d792def6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.add_sample(N=2**6,  n_cpu=-1)",
   "id": "4fe53d7e43bada10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we can first take a look on the parallel coordinate plot of all parameter values and one of the simulation outputs aggregated according to a chosen aggregation method:",
   "id": "23e24bd8271d28e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sa_study.plot_pcp(\n",
    "    aggregations={\"T_ins\": np.mean},\n",
    ")"
   ],
   "id": "16a854b3cfe48368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, let's perform a **Sobol sensitivity analysis** on the following indicator: cv_rmse on `T_ins` .\n",
    "The `analyze()` method computes Sobol indices based on a chosen performance metric—in this case, the **cv_rmse**—by comparing model predictions of `T_ins` against the provided reference time series (measured or baseline data)."
   ],
   "id": "ca2c82746fa97244"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sa_study.analyze(\n",
    "    indicator=\"T_ins\",\n",
    "    method=\"cv_rmse\",\n",
    "    reference_time_series=simulation_df_resample[\"T_ins\"],\n",
    ")"
   ],
   "id": "990ac0bb9acddf35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `plot_bar()` method displays the Sobol sensitivity indices as a bar chart, allowing a quick comparison of parameter importance.\n",
    "It uses the aggregated results from the `analyze()` step (e.g., based on `cv_rmse`) and shows  first-order indices for each parameter, making it easy to identify which parameters most influence the chosen performance metric.\n",
    "\n",
    "The sum of all the indices should be close to 1. Also, the mean confidence interval should be very low. In that case, results of the sensitivity analysis can be considered as robust."
   ],
   "id": "f5c2a855e8324d1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.plot_bar(\"T_ins\")",
   "id": "3305230bc9a51f3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The parameter epsilon appears to have the most influence on the model errors. This impact is calculated on the overall error, but will depend on the time of the day. Let's observe the parameters' impact dynamically with a 15minutes frequency.\n",
    "\n",
    "The `plot_dynamic_metric()` method extends the analysis to a frequency view of the selected performance metric.\n",
    "Here, we apply it to `T_ins` using the `cv_rmse` metric, comparing model output against the `reference_time_series` at regular intervals.\n",
    "\n",
    "Key arguments:\n",
    "- **`freq`**: Controls the temporal resolution for aggregation (e.g., `freq=\"2h\"` computes sensitivity indices every two hours). This enables tracking how parameter influence changes over time.\n",
    "- **`method`**: The metric used for comparison (here, `cv_rmse` between model predictions and the reference).\n",
    "- **`reference_time_series`**: The baseline data against which each simulation is evaluated.\n",
    "\n",
    "This approach is particularly useful in dynamic systems, where parameter importance may vary significantly across different time periods.\n",
    "\n",
    "*Calculation can take time according to the number of simulations and frequency of data.*\n"
   ],
   "id": "e53ad52d3a6e9896"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.plot_dynamic_metric(\"T_ins\", freq=\"2h\", method=\"cv_rmse\", reference_time_series=simulation_df_resample[\"T_ins\"] )",
   "id": "fd866b363245ec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1.B MORRIS method",
   "id": "a31e489e8d7ee834"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that a first screening using <code>MORRIS</code> method (as well as `RBD-FAST` and `RBD` methods)  could have been performed.",
   "id": "204bb3136c2d6d5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For <code>MORRIS</code> method, two indices, µj* for the mean of the absolute values of these effects and σj for the standard deviation of these effects, are calculated as follows:\n",
    "\n",
    "$$\n",
    "mu_{j}^{*} = \\frac{1}{r} \\sum_{i=1}^{r} E_{ij}\n",
    "$$\n",
    "\n",
    "$$\n",
    "sigma_{j} = \\sqrt{\\frac{1}{r-1} \\sum_{i=1}^{r} (E_{ij} - \\mu_{j}^{*})^2}\n",
    "$$"
   ],
   "id": "bd08f44deb200457"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.sensitivity import MorrisSanalysis\n",
    "\n",
    "sa_study = MorrisSanalysis(\n",
    "    parameters=params,\n",
    "    model=simu_PYTH,\n",
    "    simulation_options=simulation_options_PYTH,\n",
    ")"
   ],
   "id": "71c9b5fa64936e4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.add_sample(N=3**2, n_cpu=-1)",
   "id": "a9ef9dae1e1b2296",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can plot all simulations in one graph and compare the simulated internal temperature to measured T_int. Argument <code>show_legends</code> can be set to True if you want see associated parameters values.",
   "id": "8ed249dc6495c87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "dace560c00468bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.sampling import plot_sample\n",
    "\n",
    "plot_sample(\n",
    "    results=sa_study.results,\n",
    "    indicator=\"T_ins\",\n",
    "    reference_timeseries = simulation_df_resample[\"T_ins\"],\n",
    "    x_label=\"time\",\n",
    "    y_label=\"simulated temperature of T_ins [K]\",\n",
    "    show_legends=False\n",
    ")"
   ],
   "id": "d04fbd553b2ec3a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This graph can be very instructive as at some moments, simulations are far from measurements. It show that whatever the values of our parameters, it still does not fit reality: this is either due to a problem of measurement, or to our modeling approach (physical inconsistency, physical phenomenon not properly taken into account, etc.).\n",
   "id": "69c09ae315745853"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sa_study.evaluate(\n",
    "    model = simu_PYTH,\n",
    "    simulation_options=simulation_options_PYTH,\n",
    ")"
   ],
   "id": "d068e11a7572ee9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The highter $mu_{j}$, the more the parameter $j$ contributes to an uncertain output, and the higher $sigma_{j}$, the more pronounced the interaction effects between the model parameters are. Plotting $sigma_{j}$ against $mu_{j}^{}$ is often used to distinguish factors with negligible, linear, and/or interaction effects.",
   "id": "3cb2bc12ba38b9af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.plot_scatter(indicator=\"T_ins\")",
   "id": "ccd6dc275855f2be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Besides this visual interpretation, it is also possible to calculate the Euclidean distance $d$ to the origin to obtain the total effect of the uncertain parameters:",
   "id": "345e88c76ddfeebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sa_study.plot_bar(indicator=\"T_ins\")",
   "id": "6a4ceb844b59ab20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Five parameters seem to have more impact on the error than other: $alpha$, $R_{ins}$, $epsilon$, $R_{ext}$, and $R_{concrete}$. \n",
    "These results are consistant with <code>SOBOL</code> method."
   ],
   "id": "9a387a5d3c8c5cc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.4 Conclusion on sensitivity analysis\n",
    "\n",
    "The sensitivity analysis allows us to rank the influence of uncertain parameter\n",
    "on an indicator. \n",
    "\n",
    "Results with Sobol are consistant with Morris.  $epsilon$ and $alpha$ are the most influencial parameters, followed by $R_{ins}$, $R_{ext}$, and $R_{concrete}$.\n",
    "\n",
    "In the following section, we will see how to use corrai to identify the\n",
    "optimal values for these parameters in order to fit the measurement."
   ],
   "id": "76b78d1d9e64eca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Identification\n",
    "Now, we proceed to finding optimal values for these parameters by minimizing the coefficient of variation of root mean square error (cv_rmse) between one or several measured nodes, and one or several relevant outputs of our model.\n",
    "\n",
    "\n",
    "### Step-by-Step Process\n",
    "\n",
    "1. **Define the model and parameters**: by defining `OpaqueWallSimple`(this we already did) and specifying the parameters to be identify. Each parameter includes a name, an interval of possible values, a type, and an initial value.\n",
    "\n",
    "2. **Instantiate an objective function**: We create an instance of the `ObjectiveFunction` class, providing the model, simulation options, list of parameters, and indicators. The `scipy_obj_function` method of `ObjectiveFunction` will be used as the objective function for optimization. This method calculates the cv_rmse for the given parameter values.\n",
    "\n",
    "3. **Perform optimization**: We use the `minimize_scalar` function from `scipy.optimize` to minimize the objective function. Different methods can be chosen for optimization, such as Brent, bounded, and golden.\n"
   ],
   "id": "4c84cb82b435f019"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.1. Objective function\n",
    "In parameter optimization, we aim to adjust certain model parameters to minimize the difference between simulated and observed data. The objective function is a scalar function that quantifies this difference. In this case, the CV_RMSE (Coefficient of Variation of Root Mean Square Error) is used as a measure of how well the model output matches the reference measurements.\n",
    "\n",
    "**How the ObjectiveFunction Class Works** : The ObjectiveFunction class simplifies the process of optimizing model parameters by providing a structured way to:\n",
    "\n",
    "- Run simulations: For a given set of parameters, the model is simulated over the input data.\n",
    "- Calculate error metrics (e.g., CV_RMSE): The model output is compared to the reference measurements, and a scalar error metric is calculated (such as the CV_RMSE).\n",
    "Optimize: The class can then be used with optimization algorithms (like scipy.optimize or pymoo) to adjust the model parameters in order to minimize the error metric.\n",
    "Attributes of the ObjectiveFunction Class\n",
    "\n",
    "To do so, the  `ObjectiveFunction` class is designed to facilitate the optimization of model parameters using `scipy.optimize` or `pymoo` optimization methods by encapsulating the logic for simulation and indicator calculation. The `ObjectiveFunction` class takes a model, simulation options, a list of parameters to be calibrated, and a list of indicators as input. It provides methods to calculate the objective function, which can be used by optimization routines to find the optimal parameters.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "- **model**: The model to be calibrated.\n",
    "- **simulation_options**: A dictionary containing simulation options, including input data.\n",
    "- **param_list**: A list of dictionaries specifying the parameters to be calibrated.\n",
    "- **indicators_config**: A dictionary where the keys are the names of the indicators corresponding to the model outputs, and the values are either:\n",
    "    - An aggregation function to compute the indicator (e.g., np.mean, np.sum).\n",
    "    - A tuple (function, reference_data) if a comparison with reference data is required (e.g., sklearn.metrics.mean_squared_error, corrai.metrics.mae).\n",
    "- **scipy_obj_indicator**: The name of the indicator used as the objective function for optimization with scipy.optimize. By default, it is the first key in indicators_config.\n",
    "\n",
    "Let's define an anlysis daterange and redefine simulation optiouns:"
   ],
   "id": "8fa01e0b0e27f2ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feat_train = simulation_df_resample.loc[\"2024-09-04 00:00\":\"2024-09-07 00:00\"]\n",
    "\n",
    "second_index = datetime_to_seconds(feat_train.index)\n",
    "\n",
    "simulation_options_PYTH = {\n",
    "    \"dataframe\": feat_train,\n",
    "    \"startTime\": second_index[0],\n",
    "    \"endTime\": second_index[-1],\n",
    "}"
   ],
   "id": "881eb3948326386e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2. One-dimensional optimization problem",
   "id": "97d7597af7e451db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we can try scalar functions optimization from scipy (different methods: brent, boulded, golden ... see documentation on scipy website).\n",
    "For Scypi, each objective function is minimized for optimization:\n",
    "- Here we chose as indicators the temperature calculated and measured within the wall insulation. Note this could be another node (a heat flux densitiy, another temperature node).\n",
    "- The identified parameter is  $alpha$."
   ],
   "id": "323fe63a31424dcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's define a reference dictionnary, setting observation and prediction to be used for the CV_RMSE calculation. (Here they have have the same name, so it can be confusing)",
   "id": "984adbbfb7c96a81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.base.metrics import cv_rmse\n",
    "\n",
    "reference_dict = {\"T_ins\": (cv_rmse, feat_train[\"T_ins\"])}"
   ],
   "id": "ceaf13ac2715d351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We also need to set which parameter should be calibrated.",
   "id": "d1cf9c7f458228e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "calibration_params = [Parameter(\n",
    "    name='epsilon',\n",
    "    interval=(0.1, 0.8),\n",
    "    ptype=\"Real\",\n",
    "    model_property='epsilon'\n",
    ")]"
   ],
   "id": "8ca836679de47ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now instanciate an objective function, using `ObjectiveFunction`.",
   "id": "7bb570cb25cc3c66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from corrai.surrogate import ObjectiveFunction\n",
    "\n",
    "obj_func = ObjectiveFunction(\n",
    "    model=OpaqueWallSimple(),\n",
    "    simulation_options=simulation_options_PYTH,\n",
    "    parameters=calibration_params,\n",
    "    indicators_config=reference_dict,\n",
    ")"
   ],
   "id": "ff18639556ad2235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `minimize_scalar` function in `scipy.optimize` is used for scalar function minimization, specifically for one-dimensional optimization problems. This function finds the minimum value of a scalar function over a specified interval. The main methods are `Brent`, `bounded`, and `golden`.\n",
    "\n",
    "The function returns an optimization result object that contains information about the optimization process and the final solution.\n",
    "\n",
    "- **Brent** :The Brent method uses Brent’s algorithm, which combines a parabolic interpolation with the golden section search. This method does not require the interval bounds.\n",
    "- **Golden** : Employs the golden section search method, which reduces the interval of uncertainty using the golden ratio. Simple and reliable for unimodal functions, but may be slower than Brent's method.\n",
    "- **Bounded** : Restricts the search to the specified bounds using a combination of golden section search and parabolic interpolation.\n",
    "Advantages: Ensures that the solution remains within the given bounds, making it ideal for constrained problems."
   ],
   "id": "9a24e457cc8ad243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from scipy.optimize import minimize_scalar",
   "id": "33c9a83c1b01e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "result = minimize_scalar(\n",
    "    obj_func.scipy_obj_function, \n",
    "    bounds=obj_func.bounds[0],\n",
    "    method=\"Bounded\"\n",
    ")\n",
    "\n",
    "result"
   ],
   "id": "78db962a6495b017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A solution is found with a value of 0.12 for alpha and 0.36 for the CV_RMSE. Let's check if the parameter value is close to the boundaries.",
   "id": "d5092d877401ac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "obj_func.bounds",
   "id": "4cbf2fc9729e00c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is indeed not far from 0.1 but not a the limit. Let's now run the simulation using this parameter value and compare with the initial simulation.",
   "id": "26f4a8819c02136f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameter_names = [param.name for param in calibration_params]\n",
    "parameter_dict1 = {param_name: result.x for i, param_name in enumerate(parameter_names)}\n",
    "\n",
    "result_optim = simu_PYTH.simulate(\n",
    "    property_dict=parameter_dict1,\n",
    "    simulation_options=simulation_options_PYTH\n",
    ")"
   ],
   "id": "48dc0d58db1cfc5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=simulation_df_resample[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='green',\n",
    "    name=\"T_insulation - Measurement\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=init_res_PYTH[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"T_insulation - Initial results\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=result_optim[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='brown',\n",
    "    name=\"T_insulation - Optimization results\"\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Optimization vs. Measurement ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ],
   "id": "2ae801d71552398c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results are closer to measurements but still far off.",
   "id": "77aa000a449d0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.3. Multi- objectives and parameters optimization",
   "id": "679cbfeaa19bb4c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's use Pymoo, integrated into the `Problem` class of `CorrAI`  and multi-parameters optimization with multi_objectives.\n",
    "\n",
    "Note that :\n",
    "- All **objectives are minimized**.\n",
    "- All **constraints** must be provided in the form **g(x) ≤ 0** (inequalities).\n",
    "\n",
    "`Problem` aggregates all evaluator outputs into a single dictionary and then **extracts**:\n",
    "- **Objectives** in the order of `objective_ids` → matrix **F**\n",
    "- **Constraints** in the order of `constraint_ids` → matrix **G** (≤ 0)\n",
    "\n",
    "`Problem` takes as arguments:\n",
    "- **`parameters`**: as defined earlier from the class `Parameter`\n",
    "- **`evaluators`**  (or objective functions)\n",
    "- **`objective_ids`** :   Names (keys) to extract from evaluator outputs to build **F** (in order).\n",
    "- **`constraint_ids`**  : Optional names to extract for **G** (inequalities ≤ 0). If omitted, `G` is empty.\n"
   ],
   "id": "cdb92f3584436e59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3.1. Let's try with few parameters",
   "id": "1b52c09b40f97821"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frac_p = 0.20\n",
    "\n",
    "calibration_params = [\n",
    "\n",
    "    Parameter(\n",
    "        name='R_ins',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        init_value=1 / (lambda_ins / ep_ins) / 2 / S_wall,\n",
    "        relabs=\"Relative\",\n",
    "        ptype=\"Real\",\n",
    "        model_property='R_ins',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='alpha',\n",
    "        interval=(0.1, 0.9),\n",
    "        ptype=\"Real\",\n",
    "        model_property='alpha',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='epsilon',\n",
    "        interval=(0.1, 0.9),\n",
    "        ptype=\"Real\",\n",
    "        model_property='epsilon',\n",
    "    ),\n",
    "]"
   ],
   "id": "1a18680c67860070",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we can add the interferace temperature (between insulation and concrete panels) as an indicator.",
   "id": "382639dbbdf0b7f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.base.metrics import cv_rmse\n",
    "\n",
    "obj_func = ObjectiveFunction(\n",
    "    model=OpaqueWallSimple(),\n",
    "    simulation_options=simulation_options_PYTH,\n",
    "    parameters=calibration_params,\n",
    "    indicators_config={\n",
    "        \"T_ins\": (cv_rmse, feat_train[\"T_ins\"]),\n",
    "        \"T_interface\": (cv_rmse, feat_train[\"T_interface\"]),\n",
    "    },\n",
    "    scipy_obj_indicator=\"T_ins\",\n",
    ")"
   ],
   "id": "49e611448d80337b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's instanciate the problem using the classe `Problem`:",
   "id": "ef97cc58e43c40d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.multi_optimize import Problem\n",
    "\n",
    "problem = Problem(\n",
    "    parameters=calibration_params,\n",
    "    evaluators=[obj_func],\n",
    "    objective_ids=[\"T_ins\", \"T_interface\"],\n",
    ")"
   ],
   "id": "93799f08a89ee390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For a two objective problem, we choose here **NSGA2**, as a well-known multi-objective optimization algorithm based on non-dominated sorting and crowding.\n",
    "List of algorithms here https://pymoo.org/algorithms/list.html#nb-algorithms-list.\n",
    "\n",
    "If the verbose=True, some printouts during the algorithm’s execution are provided. This can very from algorithm to algorithm. Here, we execute NSGA2 on a problem where pymoo has no knowledge about the optimum. Each line represents one iteration. The first two columns are the current generation counter and the number of evaluations so far. For constrained problems, the next two columns show the minimum constraint violation (cv (min)) and the average constraint violation (cv (avg)) in the current population. This is followed by the number of non-dominated solutions (n_nds) and two more metrics which represents the movement in the objective space."
   ],
   "id": "40c58ef20557e69a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM"
   ],
   "id": "5c560de6fcd540c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "algorithm = NSGA2(\n",
    "    pop_size=50,\n",
    "    #n_offsprings=10,\n",
    "    #sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.9, eta=15),\n",
    "    mutation=PM(eta=20),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ],
   "id": "36c4a5e29c3580da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we will run 15 generation with a population of 50.",
   "id": "14d5c56706972fb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "termination = get_termination(\"n_gen\", 15)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=42,\n",
    "               verbose=True)\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (res.X, res.F))"
   ],
   "id": "e7742f7b075e7bc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's visualize the objectives functions results.",
   "id": "7023f1282a7b0398"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "Scatter().add(res.F).show()"
   ],
   "id": "5c3a4c4acc8b32f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For a bi-objective problem,and helping us chosing the best set of parameters value, we can use the decomposition method called Augmented Scalarization Function (ASF), a well-known metric in the multi-objective optimization literature.\n",
    "Let us assume the are equally important by setting the weights to 0.5 and 0.5 and setting these"
   ],
   "id": "9d9ff70f4e4e5873"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymoo.decomposition.asf import ASF\n",
    "F = res.F\n",
    "approx_ideal = F.min(axis=0)\n",
    "approx_nadir = F.max(axis=0)\n",
    "nF = (F - approx_ideal) / (approx_nadir - approx_ideal)\n",
    "\n",
    "fl = nF.min(axis=0)\n",
    "fu = nF.max(axis=0)\n",
    "weights = np.array([0.5, 0.5])\n",
    "decomp = ASF()\n",
    "\n",
    "i = decomp.do(nF, 1/weights).argmin()\n",
    "\n",
    "parameter_names = [param.name for param in calibration_params]\n",
    "parameter_dict = {param_name: res.X[i][j] for j, param_name in enumerate(parameter_names)}\n",
    "\n",
    "print(\n",
    "    \"Best regarding ASF: Point \\ni = %s\\nF = %s\" % (i,  F[i]),\n",
    "    parameter_dict\n",
    ")\n"
   ],
   "id": "3310ee8c9851ee39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The estimated parameters seem consistent with our expectations. We can compare the profile of measured indoor temperature with the output that the model predicts given the identified optimal parameters. ",
   "id": "430753101a36d277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_optim = simu_PYTH.simulate(\n",
    "    property_dict=parameter_dict,\n",
    "    simulation_options=simulation_options_PYTH,\n",
    ")"
   ],
   "id": "6af5abd476a2d1ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=simulation_df_resample[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='green',\n",
    "    name=\"T_insulation - Measurement\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=init_res_PYTH[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"T_insulation - Initial results\"\n",
    "))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=result_optim[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='brown',\n",
    "    name=\"T_insulation - Optimization results\"\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Optimization vs. Measurement ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ],
   "id": "9a396bd186cd8dce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=simulation_df_resample[\"T_interface\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='green',\n",
    "    name=\"T_interface - Measurement\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=init_res_PYTH[\"T_interface\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"T_interface - Initial results\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=result_optim[\"T_interface\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='brown',\n",
    "    name=\"T_interface - Optimization results\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Optimization vs. Measurement ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ],
   "id": "3b13a58a1375404",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3.2. All relevant parameters",
   "id": "77bd39626a63b358"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can try to identify all five parameters at once, with larger intervals.",
   "id": "bda927cd380f88d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frac_p = 0.50\n",
    "frac_conv = 0.50\n",
    "\n",
    "calibration_params = [\n",
    "    Parameter(\n",
    "        name='R_concrete',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        ptype=\"Real\",\n",
    "        init_value=1 / (lambda_concrete / ep_concrete) / 2 / S_wall,\n",
    "        relabs=\"Relative\",\n",
    "        model_property='R_concrete',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='R_ins',\n",
    "        interval=(1-frac_p, 1+frac_p),\n",
    "        init_value=1 / (lambda_ins / ep_ins) / 2 / S_wall,\n",
    "        relabs=\"Relative\",\n",
    "        ptype=\"Real\",\n",
    "        model_property='R_ins',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='alpha',\n",
    "        interval=(0.1, 0.9),\n",
    "        ptype=\"Real\",\n",
    "        model_property='alpha',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='epsilon',\n",
    "        interval=(0.1, 0.9),\n",
    "        ptype=\"Real\",\n",
    "        model_property='epsilon',\n",
    "    ),\n",
    "    Parameter(\n",
    "        name='R_ext',\n",
    "        init_value= 0.04/S_wall,\n",
    "        interval=(0.02/S_wall, 0.06/S_wall),\n",
    "        ptype=\"Real\",\n",
    "        model_property='R_ext',\n",
    "    ),\n",
    "]\n",
    "\n",
    "obj_func = ObjectiveFunction(\n",
    "    model=OpaqueWallSimple(),\n",
    "    simulation_options=simulation_options_PYTH,\n",
    "    parameters=calibration_params,\n",
    "    indicators_config={\n",
    "        \"T_ins\": (cv_rmse, feat_train[\"T_ins\"]),\n",
    "        \"T_interface\": (cv_rmse, feat_train[\"T_interface\"]),\n",
    "    },\n",
    "    scipy_obj_indicator=\"T_ins\",\n",
    ")\n",
    "\n",
    "problem = Problem(\n",
    "    parameters=calibration_params,\n",
    "    evaluators=[obj_func],\n",
    "    objective_ids=[\"T_ins\", \"T_interface\"],\n",
    ")\n",
    "\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,\n",
    "    crossover=SBX(prob=0.9, eta=15),\n",
    "    mutation=PM(eta=20),\n",
    "    eliminate_duplicates=True\n",
    ")\n",
    "\n",
    "termination = get_termination(\"n_gen\", 10)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=42,\n",
    "               verbose=True)\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (res.X, res.F))"
   ],
   "id": "a3905edeb57f7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "Scatter().add(res.F).show()"
   ],
   "id": "58a5a1ba59b54b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymoo.decomposition.asf import ASF\n",
    "F = res.F\n",
    "approx_ideal = F.min(axis=0)\n",
    "approx_nadir = F.max(axis=0)\n",
    "nF = (F - approx_ideal) / (approx_nadir - approx_ideal)\n",
    "\n",
    "fl = nF.min(axis=0)\n",
    "fu = nF.max(axis=0)\n",
    "weights = np.array([0.9, 0.1])\n",
    "decomp = ASF()\n",
    "\n",
    "i = decomp.do(nF, 1/weights).argmin()\n",
    "\n",
    "parameter_names = [param.name for param in calibration_params]\n",
    "parameter_dict2 = {param_name: res.X[i][j] for j, param_name in enumerate(parameter_names)}\n",
    "\n",
    "print(\"Best regarding ASF: Point \\ni = %s\\nF = %s\" % (i, F[i]),\n",
    "      parameter_dict2\n",
    "     )"
   ],
   "id": "d22d1be82c4dd73a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_optim2 = simu_PYTH.simulate(\n",
    "    property_dict=parameter_dict2,\n",
    "    simulation_options=simulation_options_PYTH,\n",
    ")"
   ],
   "id": "6dd3323e92a6a6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=simulation_df_resample[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='green',\n",
    "    name=\"T_insulation - Measurement\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=init_res_PYTH[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"T_insulation - Initial results\"\n",
    "))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=result_optim[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='brown',\n",
    "    name=\"T_insulation - Optimization results 1\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=init_res_PYTH.index,\n",
    "    y=result_optim2[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='pink',\n",
    "    name=\"T_insulation - Optimization results 2\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Optimization vs. Measurement ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ],
   "id": "9184271f2f7df10d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Validation set\n",
    "An important step is to check identified parameters on validation set. Let's try on an new period using the last identified values."
   ],
   "id": "4b9e79b1b72c11ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "validation_set = reference_df.loc[\"2024-09-08 00:00\":\"2024-09-14 00:00\"]\n",
    "validation_set.loc[:,\"time_sec\"] = datetime_to_seconds(validation_set.index)\n",
    "\n",
    "validation_set = validation_set.resample('5min').mean()\n",
    "second_index = datetime_to_seconds(validation_set.index)\n",
    "\n",
    "new_simulation_options_PYTH={\n",
    "    \"dataframe\":validation_set,\n",
    "    \"startTime\": second_index[0],\n",
    "    \"endTime\": second_index[-1],  \n",
    "}"
   ],
   "id": "2d5b8b9c95df81cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "validation_results = simu_PYTH.simulate(\n",
    "    parameter_dict2,\n",
    "    new_simulation_options_PYTH\n",
    ")"
   ],
   "id": "9aa4f7a4cc5c7ddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=validation_results.index,\n",
    "    y=validation_results[\"T_ins\"] ,\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='orange',\n",
    "    name=\"T_insulation - Validation result\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=validation_results.index,\n",
    "    y=validation_set[\"T_ins\"],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='green',\n",
    "    name=\"T_insulation - Measurement\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Simulation vs. Measurement ',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Temperature [K]')\n",
    "\n",
    "fig.show()"
   ],
   "id": "cad5e270e1e6ab01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cv_rmse(\n",
    "    validation_results[\"T_ins\"],\n",
    "    validation_set[\"T_ins\"]\n",
    ")"
   ],
   "id": "c894241ee9e19da6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.3.3 Mixed parameters",
   "id": "84673e7340839047"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In some calibrations, some decision variables are discrete rather than purely continuous—e.g., on/off features (booleans), choices among a few valid modes, or integers for counts. Standard continuous optimizers used earlier assume a smooth search space and therefore won’t handle these variables correctly.\n",
    "\n",
    "To reflect realistic design decisions and configuration toggles, we now introduce a model with a boolean switch (e.g., enabling/disabling a physical effect) and restrict alpha to a small set of admissible values. This mixed-variable setup better captures practical constraints and uncertainty (e.g., unknown presence of a phenomenon, or controller setpoint options), and requires a mixed-variable optimization strategy."
   ],
   "id": "f85f87661de5c8c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from corrai.base.model import Model\n",
    "\n",
    "class OpaqueWallBool(Model):\n",
    "    def simulate(\n",
    "        self,\n",
    "        property_dict: dict,\n",
    "        simulation_options: dict,\n",
    "        simulation_kwargs: dict | None = None,\n",
    "        **kwargs,\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        default_parameters = {\n",
    "            \"R_ext\": 0.005,\n",
    "            \"R_int\": 0.01,\n",
    "            \"R_concrete\": 0.10,\n",
    "            \"R_ins\": 0.32,\n",
    "            \"C_concrete\": 2.95e6,\n",
    "            \"C_ins\": 3.64e4,\n",
    "            \"alpha\": 0.2,\n",
    "            \"S_wall\": 7,\n",
    "            \"epsilon\": 0.4,\n",
    "            \"fview\": 0.5,\n",
    "            \"has_LW_radiation\": True\n",
    "        }\n",
    "        parameters = {**default_parameters, **property_dict}\n",
    "\n",
    "        R_ext       = parameters[\"R_ext\"]\n",
    "        R_int       = parameters[\"R_int\"]\n",
    "        R_concrete  = parameters[\"R_concrete\"]\n",
    "        R_ins       = parameters[\"R_ins\"]\n",
    "        C_concrete  = parameters[\"C_concrete\"]\n",
    "        C_ins       = parameters[\"C_ins\"]\n",
    "        alpha       = parameters[\"alpha\"]\n",
    "        S_wall      = parameters[\"S_wall\"]\n",
    "        epsilon     = parameters[\"epsilon\"]\n",
    "        fview       = parameters[\"fview\"]\n",
    "        has_LW_radiation = parameters[\"has_LW_radiation\"]\n",
    "\n",
    "        sigma = 5.67e-8  # W/m^2/K^4\n",
    "\n",
    "        df = simulation_options[\"dataframe\"]\n",
    "        time  = df[\"time_sec\"].values\n",
    "        T_ext = df[\"T_ext\"].values\n",
    "        T_int = df[\"T_int\"].values\n",
    "        Q_rad = df[\"Pyr\"].values\n",
    "\n",
    "        startTime = simulation_options.get(\"startTime\", time[0])\n",
    "        stopTime  = simulation_options.get(\"stopTime\",  time[-1])\n",
    "\n",
    "        mask  = (time >= startTime) & (time <= stopTime)\n",
    "        time  = time[mask]\n",
    "        T_ext = T_ext[mask]\n",
    "        T_int = T_int[mask]\n",
    "        Q_rad = Q_rad[mask]\n",
    "\n",
    "        # init\n",
    "        T_se        = np.zeros(len(time))\n",
    "        T_concrete  = np.zeros(len(time))\n",
    "        T_ins       = np.zeros(len(time))\n",
    "        T_interface = np.zeros(len(time))\n",
    "        T_si        = np.zeros(len(time))\n",
    "        T_sky       = np.zeros(len(time))\n",
    "\n",
    "        T_se[0]        = T_ext[0]\n",
    "        T_concrete[0]  = 299\n",
    "        T_ins[0]       = T_int[0]\n",
    "        T_interface[0] = (T_ins[0] + T_concrete[0]) / 2\n",
    "        T_si[0]        = T_int[0]\n",
    "        T_sky[0]       = T_int[0]\n",
    "\n",
    "        for t in range(1, len(time)):\n",
    "            dt = time[t] - time[t - 1]\n",
    "\n",
    "\n",
    "            ## boolean to turn off long wave radiation exchange with environnement and sky\n",
    "            T_sky[t] = 0.0552 * (T_ext[t] ** 1.5) if has_LW_radiation else 0.0\n",
    "\n",
    "            Q_rad_sky = (\n",
    "                epsilon * fview * sigma * (T_se[t - 1] ** 4 - T_sky[t] ** 4) * S_wall\n",
    "                if has_LW_radiation else 0.0\n",
    "            )\n",
    "            Q_rad_amb = (\n",
    "                epsilon * fview * sigma * (T_se[t - 1] ** 4 - T_ext[t - 1] ** 4) * S_wall\n",
    "                if has_LW_radiation else 0.0\n",
    "            )\n",
    "            Q_rad_dir = Q_rad[t - 1] * alpha * S_wall\n",
    "\n",
    "            T_se[t] = (\n",
    "                T_ext[t - 1] / R_ext\n",
    "                + T_ins[t - 1] / (R_ins / 2)\n",
    "                + Q_rad_dir - Q_rad_sky - Q_rad_amb\n",
    "            ) / (1 / R_ext + 1 / (R_ins / 2))\n",
    "\n",
    "            T_interface[t] = (\n",
    "                T_ins[t - 1] / (R_ins / 2) + T_concrete[t - 1] / (R_concrete / 2)\n",
    "            ) / (1 / (R_concrete / 2) + 1 / (R_ins / 2))\n",
    "\n",
    "            T_si[t] = (\n",
    "                T_int[t - 1] / R_int + T_concrete[t - 1] / (R_concrete / 2)\n",
    "            ) / (1 / R_int + 1 / (R_concrete / 2))\n",
    "\n",
    "            T_ins[t] = T_ins[t - 1] + dt / C_ins * (\n",
    "                (T_se[t] - T_ins[t - 1]) / (R_ins / 2)\n",
    "                + (T_interface[t] - T_ins[t - 1]) / (R_ins / 2)\n",
    "            )\n",
    "\n",
    "            T_concrete[t] = T_concrete[t - 1] + dt / C_concrete * (\n",
    "                (T_interface[t] - T_concrete[t - 1]) / (R_concrete / 2)\n",
    "                + (T_si[t] - T_concrete[t - 1]) / (R_concrete / 2)\n",
    "            )\n",
    "\n",
    "        # output\n",
    "        df_out = pd.DataFrame(\n",
    "            {\n",
    "                \"T_concrete\":  T_concrete,\n",
    "                \"T_interface\": T_interface,\n",
    "                \"T_ins\":       T_ins,\n",
    "            },\n",
    "            index=df.index[mask],\n",
    "        )\n",
    "        self.simulation_options = simulation_options\n",
    "        return df_out"
   ],
   "id": "77844027c51e6f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mixed_params = [\n",
    "    Parameter(name=\"alpha\", values=(0.2, 0.4, 0.5), ptype=\"Choice\", model_property=\"alpha\"),\n",
    "    Parameter(name=\"epsilon\", interval=(0, 1), ptype=\"Real\", model_property=\"epsilon\"),\n",
    "    Parameter(name=\"has_LW_radiation\", ptype=\"Binary\", model_property=\"has_LW_radiation\"),\n",
    "]"
   ],
   "id": "f38515d84c5b71cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corrai.multi_optimize import Problem\n",
    "\n",
    "obj_func = ObjectiveFunction(\n",
    "    model=OpaqueWallBool(),\n",
    "    simulation_options=simulation_options_PYTH,\n",
    "    parameters=mixed_params,\n",
    "    indicators_config={\n",
    "        \"T_ins\": (cv_rmse, feat_train[\"T_ins\"]),\n",
    "    },\n",
    "    scipy_obj_indicator=\"T_ins\",\n",
    ")\n",
    "\n",
    "problem = Problem(\n",
    "    parameters=mixed_params,\n",
    "    evaluators=[obj_func],\n",
    "    objective_ids=[\"T_ins\"],\n",
    ")"
   ],
   "id": "b2801bfaec82fcd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymoo.termination import get_termination\n",
    "from pymoo.algorithms.moo.nsga2 import RankAndCrowdingSurvival\n",
    "from pymoo.core.mixed import MixedVariableGA\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "algorithm = MixedVariableGA(pop_size=50, survival=RankAndCrowdingSurvival())\n",
    "termination = get_termination(\"n_gen\", 5)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=42,\n",
    "               verbose=True)\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (res.X, res.F))"
   ],
   "id": "6c69db5bf099ef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c1003131b39bbf24",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
