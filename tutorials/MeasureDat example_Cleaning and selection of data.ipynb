{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f8dc4",
   "metadata": {},
   "source": [
    "---\n",
    "# Loading and processing measured data with MeasuredDats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae542b-fc43-449a-98a1-6e911cef0a28",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to provide a comprehensive workflow for treating measured data on a test bench using  **CorrAI** <code>MeasuredDats</code>. \n",
    "At first sight, a dataset may look fine, but missing values or incorrect variations are not always visible. The following steps are proposed to ensure data quality.\n",
    "\n",
    "#### 1- Identify anomalies:\n",
    "Purpose: Establish boundaries for acceptable data values and rates of change.\n",
    "- __upper__ and __lower values__  as boundaries: Define permissible ranges for measured values. Data points outside these ranges are flagged as anomalies.\n",
    "- __upper__ and __lower \"rates__\" :  Set thresholds for acceptable rates of change in measured values over time. Values exceeding these thresholds indicate anomalies.\n",
    "\n",
    "#### 2- Missing data interpolation\n",
    "Purpose: Ensure continuity and reliability of data for analysis.\n",
    "- __Interpolation Methods__: Use techniques like linear interpolation to estimate missing data points between known values.\n",
    "- __Handling Edge Cases__: Correct errors at the start or end of a time series by extrapolating from the first or last known value.\n",
    "\n",
    "Physical models and analytical tools usually require complete data sets.\n",
    "\n",
    "#### 3- Selecting dataset for modelling\n",
    "Purpose: Manage large datasets effectively and select relevant set of information.\n",
    "\n",
    "- __Resampling__: Aggregate data into larger time intervals (e.g., from 1-minute to 10-minute intervals) using resampling techniques.\n",
    "- __Selection Criteria__: Choose optimal time intervals based on system requirements and modeling resolution. For example, select days with consistent weather conditions.\n",
    "\n",
    "By following these steps in your data treatment workflow with CorrAI, you can enhance the reliability and usability of your measured data for  analysis and modeling.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85508d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Use case\n",
    "\n",
    "The data used here are measurements collected from a real-scale benchmark conducted by Nobatek's BEF (Banc d'Essais Façade), which provides experimental cells for testing building façade solutions. Heat exchanges in a cell are limited to five of its faces, while the sixth face is dedicated to the tested solution. Internal temperature and hydrometry conditions can be controlled or monitored, and external conditions, such as temperatures and solar radiation, are measured.\n",
    "\n",
    "The experimental setup is presented in the following figures:\n",
    "\n",
    "| Figure 1: picture of the benchmark | Figure 2: wall layers from the inside (right) to the outside (left) |\n",
    "| :---: | :---: |\n",
    "|<img src=\"images/etics_pict.png\"  height=\"300\"> | <img src=\"images/etics_sch.png\"  height=\"300\"> |\n",
    "\n",
    "Additional details about the data:\n",
    "- The measurement campaign spanned from 13/12/2017 to 13/06/2018.\n",
    "- The acquisition timestep is around 1 minute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768a5bb",
   "metadata": {},
   "source": [
    "# Measured data analysis and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bac0",
   "metadata": {},
   "source": [
    "Measured data are loaded using <code>pandas</code> python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    Path(r\"resources/tuto_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c929",
   "metadata": {},
   "source": [
    "Plotting the raw temperatures gives precious information on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc901bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['T_ext'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe828d3-e1d3-4f6d-b606-0c70d51b249a",
   "metadata": {},
   "source": [
    "However, missing values or incorrect variations are not always visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae77f39",
   "metadata": {},
   "source": [
    "## Using Class MeasuredDat to perform operations on data\n",
    "\n",
    "The <code>MeasuredDats</code> **corrai** object is designed to specify transformations to apply to a measured dataset and to visualize their effects.\n",
    "The measurements are classified in _categories_ (eg. temperature, power, control, etc.).\n",
    "There are 3 kinds of transformations :\n",
    "- _Category level_: specify transformations \"in parallel\" that will be applied to specified categories\n",
    "- _Common transformation_: apply transformation to all categories\n",
    "- _Resampling_: process data using a time rule and an aggregation method. It may be used to align data on a regular time index or reduce the size of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460e850-7193-4ee3-8feb-6b3ab6781311",
   "metadata": {},
   "source": [
    "#### Presentation of MeasuredDats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466f8b9",
   "metadata": {},
   "source": [
    "The <code>MeasuredDats</code> **corrai** object is designed to specify transformations to apply to a measured dataset and to visualize their effects.\n",
    "The measurements are classified in _categories_ (eg. temperature, power, control, etc.).\n",
    "There are 3 kinds of transformations :\n",
    "- _Category level_: specify transformations \"in parallel\" that will be applied to specified categories\n",
    "- _Common transformation_: apply transformation to all categories\n",
    "- _Resampling_: process data using a time rule and an aggregation method. It may be used to align data on a regular time index or reduce the size of the dataset\n",
    "\n",
    "**** Presentation of MeasuredDats\n",
    "\n",
    "<code>MeasuredDats</code> uses **Scikit Learn** _pipelines_. The transformers are <code>corrai.custom_transfomers</code> objects, they inherit from scikit base class <code>BaseEstimator</code> and <code>TransformerMixin</code>. These transformer ensure that Pandas <code>DataFrame</code> with <code>DateTimeIndex</code> are used through the process\n",
    "\n",
    "You can list the transformers keys from <code>corrai.measure.Transformer</code>.\n",
    "\n",
    "Refer to <code>corrai.transformers</code> documentation to configure transformers arguments.\n",
    "\n",
    "The figure below describes a \"pipeline\" that apply a series of corrections to the dataset.\n",
    "\n",
    "<img src=\"images/pipe.png\"  height=\"300\">\n",
    "\n",
    "4 successive transformations are applied: 2 category transformations, a common transformation and a resampling operation.\n",
    "\n",
    "The **categories** are specified using <code>data_type_dict</code> :\n",
    "```\n",
    "category_dict = {\n",
    "    \"Temperatures\": [\"temp_1\", \"temp_2\"],\n",
    "    \"Power\": [\"pow_1\"],\n",
    "    \"radiation\": [\"Sol_rad\"]\n",
    "    }\n",
    "```\n",
    "\n",
    "The **category transformations** are specified using <code>category_transformations</code> :\n",
    "```\n",
    "category_transformations = {\n",
    "    \"Temperatures\":{\n",
    "        \"ANOMALIES\": [\n",
    "            [Transformer.DROP_THRESHOLD, {\"upper\": 40000, \"lower\": 0}],\n",
    "            [Transformer.DROP_TIME_GRADIENT, {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "    },\n",
    "    \"Power\": {\n",
    "        \"ANOMALIES\": [\n",
    "            [Transformer.DROP_THRESHOLD, {\"upper\": 50, \"lower\": -2}],\n",
    "            [Transformer.DROP_TIME_GRADIENT, {\"upper_rate\": 5000, \"lower_rate\": 0}],\n",
    "        ],\n",
    "        \"PROCESS\": [\n",
    "            [Transformer.APPLY_EXPRESSION, {\"expression\": \"X / 1000\"}]\n",
    "        ],\n",
    "    },\n",
    "    \"radiation\": {}\n",
    "},\n",
    "```\n",
    "\n",
    "- The dictionary keys must match the category defined in <code>category_dict</code>\n",
    "- For each category you can specify as much transformer as you want. Similar name must be given in each category if you want transformer to be used in the same _\"category transformation\"_ (eg. ANOMALIES)\n",
    "- For each transformer a list of transformation is given. They are defined by a list with two elements [custom_transformer key, {custom transformer args}]\n",
    "- If the category doesn't require any transformation, specify an empty dictionary\n",
    "\n",
    "The **common transformations** are specified using <code>common_transformations</code>:\n",
    "\n",
    "```\n",
    "common_transformations={\n",
    "    \"COMMON\": [\n",
    "        [Transformer.INTERPOLATE, {\"method\": 'linear'}],\n",
    "        [Transformer.FILL_NA, {\"method\": 'bfill'}]\n",
    "    ]\n",
    "}\n",
    "```\n",
    "- The dictionary keys are the names of the common transformers\n",
    "- For each transformer, a list of transformations is given. They are defined by a list of two elements [custom_transformer key, {custom transformer args}]\n",
    "\n",
    "The **Resampler** is configured as follows:\n",
    "```\n",
    "resampler_agg_methods={\n",
    "    \"Temperatures\": AggMethod.MEAN\n",
    "}\n",
    "```\n",
    "\n",
    "- An optional key \"RESAMPLE\" may be given to specify the category aggregation method in case of resampling. By default, resampling method is _mean_. If you want \"mean\" for all categories, an empty dictionary may be specified (default value).\n",
    "\n",
    "\n",
    "The **transformer list** :\n",
    "Lastly you can specify the order of the transformations using <code>transformers_list</code>. For example <code>transformers_list = [\"ANOMALIES\", \"COMMON\", \"RESAMPLER\", \"PROCESS\"]</code>\n",
    "- If <code>transformer_list</code> is left to <code>None</code>, transformers list hold all the category_transformers, than all the common transformers\n",
    "- If <code>\"RESAMPLER\"</code> is not present in <code>transformer_list</code>, but a <code>resampling_rule</code> is provided, the <code>\"RESAMPLER\"</code> will automatically be added at the end of the <code>transformers_list</code>\n",
    "- This list can be changed at all time\n",
    "- You don't have to use all the transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256a228",
   "metadata": {},
   "source": [
    "Below is an example for the dataset we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.measure import MeasuredDats, Transformer, AggMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f28fed",
   "metadata": {},
   "source": [
    "You can print the list of all available transformers from the class <code>Transformer</code> (using enums) to help you configure <code>MeasuredDats</code>. More information on these transformers are available in the <code>corrai.measure.py</code> script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45eaeeb",
   "metadata": {},
   "source": [
    "Likewise, you can check the available aggregation methods from the class <code>AggMethod</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(AggMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f879ab8-d831-40cc-a183-ff6216cd3d76",
   "metadata": {},
   "source": [
    "Let's first instanciate MeasuredDats, providing :\n",
    "- the dataframe\n",
    "- a dictionary mapping data categories to  column name\n",
    "- transformations (common transformation and resamplers)\n",
    "- and a transformers list, provinding the order of transformation (RESAMPLE at the end by Defaults).s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MeasuredDats(\n",
    "    data = raw_data,\n",
    "    category_dict = {\n",
    "        \"temperatures\": [\n",
    "            'T_Wall_Ins_1', 'T_Wall_Ins_2', 'T_Ins_Ins_1', 'T_Ins_Ins_2',\n",
    "            'T_Ins_Coat_1', 'T_Ins_Coat_2', 'T_int_1', 'T_int_2', 'T_ext', 'T_garde'\n",
    "        ],\n",
    "        \"illuminance\": [\"Lux_CW\"],\n",
    "        \"radiation\": [\"Sol_rad\"]\n",
    "    },\n",
    "    category_transformations = {\n",
    "        \"temperatures\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [Transformer.DROP_THRESHOLD, {\"upper\": 100, \"lower\": -20}],\n",
    "                [Transformer.DROP_TIME_GRADIENT, {\"upper_rate\": 2, \"lower_rate\": 0}]\n",
    "            ],\n",
    "        },\n",
    "        \"illuminance\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [Transformer.DROP_THRESHOLD, {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "        },\n",
    "        \"radiation\": {\n",
    "            \"ANOMALIES\": [\n",
    "                [Transformer.DROP_THRESHOLD, {\"upper\": 1000, \"lower\": 0}],\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    common_transformations={\n",
    "        \"COMMON\": [\n",
    "            [Transformer.INTERPOLATE, {\"method\": 'linear'}],\n",
    "            [Transformer.BFILL, {}],\n",
    "        ]\n",
    "    },\n",
    "    transformers_list=[\"ANOMALIES\", \"COMMON\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee27fd",
   "metadata": {},
   "source": [
    "Note that <code>transformers_list</code> could have been left to None. Here, we are applying the _anomalies_ transformer, then the _common_ transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c1647-b898-434d-92fc-280e4bad3f1e",
   "metadata": {},
   "source": [
    "#### 1. Identify anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54297b",
   "metadata": {},
   "source": [
    "The <code>plot</code> method can be used to plot the data. Provide a <code>list</code> to the argument <code>cols</code> to specify the entries you want to plot. A new y axis will be created for each data type. Choose begin and end dates for specific days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac115e7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-04-15',\n",
    "    end='2018-04-18',\n",
    "    title='Plot uncorrected data',\n",
    "    marker_raw=True,\n",
    "    line_raw=False,\n",
    "    plot_raw = True,\n",
    "    resampling_rule='15min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e79b06",
   "metadata": {},
   "source": [
    "Plotted data are the <code>corrected_data</code> obtained after going through the pipeline described in the <code>MeasuredDats</code> object's <code>transformers_list</code>. You can specify an alternative transformers_list using the <code>plot</code> function argument <code>transformers_list</code>.\n",
    "\n",
    "Use <code>plot_raw=True</code> to display raw data. This is useful to assess the impact of the correction and of the resampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3932",
   "metadata": {},
   "source": [
    "\n",
    "The <code>get_missing_values_stats</code> method gives information on the amount of missing values.\n",
    "You can get it for raw, corrected or partially corrected data depending on the transformers specified in <code>transformers_list</code>.\n",
    "\n",
    "Let's have a look for raw data. We specify an empty <code>transformers_list</code> that create a pipeline with a single Identity transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats(transformers_list=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555a612-947e-4cf0-b6a6-a3467c877062",
   "metadata": {},
   "source": [
    "Before correction, the journal shows that ~2% of the data is missing for the temperature sensor and ~3% for external temperature, \"garde\" temperature and solar radiation. It corresponds to data having a timestamp, but with missing value. In this specific case, this is not related to sensors errors. 2 distinct acquisition device were used to perform the measurement. The merging of the data from the two devices created troubles in timestamp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b3561-ea95-436d-85f6-5d2487224f69",
   "metadata": {},
   "source": [
    "Now let's apply the ANOMALIES transformer to delete invalid data according to the specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386abd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats([\"ANOMALIES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd878",
   "metadata": {},
   "source": [
    "It looks like the applied corrections removed several data.\n",
    "For example, the sensors measuring the cell internal temperature have now up to __4.6%__ of missing data.\n",
    "\n",
    "Few corrections were applied to the outside temperature sensor.\n",
    "\n",
    "The journal of correction holds further information on the gaps of data.\n",
    "For example, we might want to know more about the missing values of <code>T_int_1</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_gaps_description(cols=[\"T_int_1\"], transformers_list=[\"ANOMALIES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b3f59",
   "metadata": {},
   "source": [
    "- There are 11220 gaps\n",
    "- 75% of these gaps do not exceed 1 timestep (~1min)\n",
    "- The longest is 1h\n",
    "\n",
    "It is also possible to \"aggregate\" the gaps to know when at least one of the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_gaps_description(transformers_list=[\"ANOMALIES\"])[\"combination\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c767b8",
   "metadata": {},
   "source": [
    "- There are 28007 gaps (~10% of the dataset).\n",
    "- The size of 75% of these gaps do not exceed 2 minutes\n",
    "- The biggest gap lasts about 1 hour\n",
    "\n",
    "There is not a lot of difference. It looks like the values are missing at the same timestamps. This is good news, it means that there are a lot of periods with all data available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275e599",
   "metadata": {},
   "source": [
    "The plotting method <code>plot_gaps</code> can be used to visualize where the gap(s) happened.\n",
    "\n",
    "This dataset holds a lot of values, hence we only plot the input <code>'T_int_1'</code> here, as it is supposed to have the more gaps.\n",
    "\n",
    "We are interested in gaps lasting more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88573e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "my_data.plot_gaps(\n",
    "    cols=['T_Wall_Ins_1', 'Sol_rad', 'Lux_CW'],\n",
    "    begin='2018-03-25',\n",
    "    end='2018-03-25',\n",
    "    gaps_timestep=dt.timedelta(minutes=15),\n",
    "    transformers_list=[\"ANOMALIES\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f229b95",
   "metadata": {},
   "source": [
    "There seem to be only 1 gap greater than 15 minutes, it happens the 2018-03-25 between ~02:00 and ~3:00.\n",
    "This is the gap we identified in the correction journal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7b15",
   "metadata": {},
   "source": [
    "#### 2- Missing data interpolation\n",
    "In our example, the same method is used to fill the gaps for all categories.\n",
    "It is described in <code>common_transformations</code>\n",
    "Below is the object transformers list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.transformers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799dc35",
   "metadata": {},
   "source": [
    "To get the corrected data, we just need to call <code>get_corrected_data</code> method, with default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_corrected_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c870f",
   "metadata": {},
   "source": [
    "We can check the effect of the transformation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_missing_value_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf064",
   "metadata": {},
   "source": [
    "Wow, perfect dataset !\n",
    "\n",
    "**Be careful** Having zero missing data doesn't imply zero issues; a dataset that was initially of poor quality remains so even if gaps are filled by copying values or interpolating between (_what seems to be_) valid points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3effa3",
   "metadata": {},
   "source": [
    "#### 3- Reducing the dataset size\n",
    "As we noted earlier, 1 min timestep is too small.\n",
    "Regarding the physical phenomenon involved here, we could say that 5min is ok.\n",
    "Let's have a look at the corrected data versus the raw data.\n",
    "We select a period around the gap we identified (from the 2018-03-24 to the 2018-03-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feafd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1'],\n",
    "    begin='2018-03-24 00:00:00',\n",
    "    end='2018-03-26 05:00:00',\n",
    "    plot_raw=True,\n",
    "    plot_corrected=True,\n",
    "    line_raw=False,\n",
    "    marker_corrected=False,\n",
    "    resampling_rule='5min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ab339",
   "metadata": {},
   "source": [
    "On the above graph, you can see the effects of mean resampling, that diminishes the number of points and smooths out the data.\n",
    "\n",
    "The gap have been filled out, using linear interpolation at the required timestep. It is important to compare your data before and after applying the correction methods. Resampling with a large timestep can lead to a loss of information. \n",
    "Depending on the modelkkbg aoori\n",
    "For modelling considerations, let's select two datasets containing days with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405bfcb-db04-4d3a-bda6-e18383db8138",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f0ff1-0c9d-4936-9482-ba865da78c0e",
   "metadata": {},
   "source": [
    "Each dataset selection should be guided by the specific requirements of the modeling approach, ensuring that the data provided fits the analytical framework but also enhances the model’s predictive capability and applicability to real-world scenarios.\n",
    " \n",
    "Datasets characterized by prolonged periods of stable external conditions such as consistent temperatures without significant fluctuations, will be prioritized for steady-state modeling. For dynamic modeling applications — where system responses to varying inputs over time are crucial — datasets with diverse environmental profiles(varying solar radiation intensities across different days and seasons) should be preferred. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc951dd-1f96-4622-bbd9-e47402187ae7",
   "metadata": {},
   "source": [
    "For instance, here is a plot during winter, with rather cold outside temperatures, and days with different profiles of solar radiations (from low to high values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403eb4b0-9073-473a-8f27-8c709b284604",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1', \"T_ext\", \"Sol_rad\" ],\n",
    "    begin='2018-01-09 00:00:00',\n",
    "    end='2018-01-11 23:00:00',\n",
    "    plot_raw=True,\n",
    "    plot_corrected=True,\n",
    "    line_raw=False,\n",
    "    marker_corrected=False,\n",
    "    resampling_rule='5min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c26452-f61d-4aaa-8ea2-f3bad150261c",
   "metadata": {},
   "source": [
    "Alternatively, if we aim to characterize the wall according to ISO 9869-1:2023, which mandates steady temperatures during nighttime and a significant temperature difference between indoor and outdoor environments (>10 or 15 K), the measurements from the following nights would be pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89101b-c392-4bea-a12e-0adb3218be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.plot(\n",
    "    title=\"Raw data versus corrected data\",\n",
    "    cols=['T_int_1', \"T_ext\", \"Sol_rad\" ],\n",
    "    begin='2018-03-25 00:00:00',\n",
    "    end='2018-03-28 23:00:00',\n",
    "    plot_raw=True,\n",
    "    plot_corrected=True,\n",
    "    line_raw=False,\n",
    "    marker_corrected=False,\n",
    "    resampling_rule='5min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2442c67-e045-4cfd-baa1-5a45a673fb30",
   "metadata": {},
   "source": [
    "For future use, the corrected data during a period of interest can be saved with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198769e-b58f-4813-a860-ceca00292e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.get_corrected_data(resampling_rule=\"5min\").loc[\"2018-01-09\":\"2018-01-11\"].to_csv(\n",
    "    \"resources/3day_study_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59334ae-6e1d-48bc-a685-d5284cace375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
